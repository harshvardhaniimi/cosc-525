{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:48.637923Z",
     "iopub.status.busy": "2023-05-06T22:23:48.637072Z",
     "iopub.status.idle": "2023-05-06T22:23:50.765299Z",
     "shell.execute_reply": "2023-05-06T22:23:50.764760Z",
     "shell.execute_reply.started": "2023-05-06T22:23:48.637527Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 18:23:48.882794: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-06 18:23:48.932136: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:52.683140Z",
     "iopub.status.busy": "2023-05-06T22:23:52.682837Z",
     "iopub.status.idle": "2023-05-06T22:23:52.910540Z",
     "shell.execute_reply": "2023-05-06T22:23:52.909702Z",
     "shell.execute_reply.started": "2023-05-06T22:23:52.683121Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense, Flatten\n",
    "from tensorflow.keras.models import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions to Load Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:53.515971Z",
     "iopub.status.busy": "2023-05-06T22:23:53.515614Z",
     "iopub.status.idle": "2023-05-06T22:23:53.521123Z",
     "shell.execute_reply": "2023-05-06T22:23:53.520360Z",
     "shell.execute_reply.started": "2023-05-06T22:23:53.515952Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_labels_and_dataframe(path, train_csv, val_csv):\n",
    "    # Load the CSV files\n",
    "    train_df = pd.read_csv(os.path.join(path, train_csv))\n",
    "    val_df = pd.read_csv(os.path.join(path, val_csv))\n",
    "    \n",
    "    # Encode the categorical labels\n",
    "    age_encoder = LabelEncoder()\n",
    "    gender_encoder = LabelEncoder()\n",
    "    race_encoder = LabelEncoder()\n",
    "\n",
    "    train_df['age'] = age_encoder.fit_transform(train_df['age'])\n",
    "    train_df['gender'] = gender_encoder.fit_transform(train_df['gender'])\n",
    "    train_df['race'] = race_encoder.fit_transform(train_df['race'])\n",
    "\n",
    "    val_df['age'] = age_encoder.transform(val_df['age'])\n",
    "    val_df['gender'] = gender_encoder.transform(val_df['gender'])\n",
    "    val_df['race'] = race_encoder.transform(val_df['race'])\n",
    "    \n",
    "    return train_df, val_df, age_encoder, gender_encoder, race_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:54.092690Z",
     "iopub.status.busy": "2023-05-06T22:23:54.092138Z",
     "iopub.status.idle": "2023-05-06T22:23:54.100157Z",
     "shell.execute_reply": "2023-05-06T22:23:54.099020Z",
     "shell.execute_reply.started": "2023-05-06T22:23:54.092650Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for all data\n",
    "def load_data(path, input_shape):\n",
    "    train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    train_gen = train_datagen.flow_from_directory(\n",
    "        os.path.join(path, 'train'),\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    val_gen = val_datagen.flow_from_directory(\n",
    "        os.path.join(path, 'val'),\n",
    "        target_size=input_shape[:2],\n",
    "        batch_size=32,\n",
    "        class_mode='categorical'\n",
    "    )\n",
    "\n",
    "    return train_gen, val_gen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:54.733284Z",
     "iopub.status.busy": "2023-05-06T22:23:54.732277Z",
     "iopub.status.idle": "2023-05-06T22:23:54.752639Z",
     "shell.execute_reply": "2023-05-06T22:23:54.751102Z",
     "shell.execute_reply.started": "2023-05-06T22:23:54.733212Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_images(df, path, input_shape):\n",
    "    images = []\n",
    "    for _, row in df.iterrows():\n",
    "        img_path = os.path.join(path, row['file'])\n",
    "        img = load_img(img_path, target_size=input_shape[:2])\n",
    "        img_arr = img_to_array(img) / 255.0\n",
    "        images.append(img_arr)\n",
    "    return np.array(images)\n",
    "\n",
    "def load_sample_data(path, input_shape, train_csv, val_csv, sample_percent=0.1):\n",
    "    # Load the dataframes and label encoders\n",
    "    train_df, val_df, age_encoder, gender_encoder, race_encoder = load_labels_and_dataframe(path, \n",
    "                                                                                            \"fairface_label_\"+train_csv, \n",
    "                                                                                            \"fairface_label_\"+val_csv)\n",
    "\n",
    "    # Take a fraction of the dataset\n",
    "    train_df = train_df.sample(frac=sample_percent)\n",
    "    val_df = val_df.sample(frac=sample_percent)\n",
    "\n",
    "    # Load the images and labels\n",
    "    train_images = load_images(train_df, path, input_shape)\n",
    "    train_labels = train_df[[\"age\", \"gender\", \"race\"]].values\n",
    "    val_images = load_images(val_df, path, input_shape)\n",
    "    val_labels = val_df[[\"age\", \"gender\", \"race\"]].values\n",
    "\n",
    "    return train_images, train_labels, val_images, val_labels, age_encoder, gender_encoder, race_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Autoencoder and Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:55.149008Z",
     "iopub.status.busy": "2023-05-06T22:23:55.148130Z",
     "iopub.status.idle": "2023-05-06T22:23:55.161326Z",
     "shell.execute_reply": "2023-05-06T22:23:55.160102Z",
     "shell.execute_reply.started": "2023-05-06T22:23:55.148963Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_shape):\n",
    "    input_img = Input(shape=input_shape)\n",
    "\n",
    "    # Encoder\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "    # Decoder\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(encoded)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "    autoencoder = Model(input_img, decoded)\n",
    "    return autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:55.797866Z",
     "iopub.status.busy": "2023-05-06T22:23:55.796986Z",
     "iopub.status.idle": "2023-05-06T22:23:55.804568Z",
     "shell.execute_reply": "2023-05-06T22:23:55.803098Z",
     "shell.execute_reply.started": "2023-05-06T22:23:55.797812Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def extract_encoder(autoencoder):\n",
    "    # Extract the encoder layers from the autoencoder model\n",
    "    input_img = autoencoder.input\n",
    "    # Assuming the encoder layers are the first 5 layers\n",
    "    encoded = autoencoder.layers[5].output\n",
    "\n",
    "    # Create a new model with the encoder layers\n",
    "    encoder = Model(input_img, encoded)\n",
    "\n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:56.303708Z",
     "iopub.status.busy": "2023-05-06T22:23:56.303038Z",
     "iopub.status.idle": "2023-05-06T22:23:56.313587Z",
     "shell.execute_reply": "2023-05-06T22:23:56.312350Z",
     "shell.execute_reply.started": "2023-05-06T22:23:56.303657Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_classification_model(encoder, num_race_classes, num_age_classes, num_gender_classes):\n",
    "    # Use the encoder's output as input for the classification model\n",
    "    encoded_input = encoder.output\n",
    "\n",
    "    # Add a Flatten layer to convert the feature maps into a 1D vector\n",
    "    x = Flatten()(encoded_input)\n",
    "\n",
    "    # Add Dense layers for classification\n",
    "    x = Dense(256, activation='relu')(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "\n",
    "    # Add output layers for each attribute: race, age, and gender\n",
    "    race_output = Dense(num_race_classes, activation='softmax', name='race_output')(x)\n",
    "    age_output = Dense(num_age_classes, activation='softmax', name='age_output')(x)\n",
    "    gender_output = Dense(num_gender_classes, activation='softmax', name='gender_output')(x)\n",
    "\n",
    "    # Create the classification model\n",
    "    classification_model = Model(encoder.input, [race_output, age_output, gender_output])\n",
    "\n",
    "    return classification_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Model for Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:23:57.676660Z",
     "iopub.status.busy": "2023-05-06T22:23:57.675979Z",
     "iopub.status.idle": "2023-05-06T22:23:57.685273Z",
     "shell.execute_reply": "2023-05-06T22:23:57.684058Z",
     "shell.execute_reply.started": "2023-05-06T22:23:57.676608Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_in_batches(encoder, data, batch_size):\n",
    "    num_batches = int(np.ceil(len(data) / batch_size))\n",
    "    predictions = []\n",
    "\n",
    "    for i in range(num_batches):\n",
    "        start_idx = i * batch_size\n",
    "        end_idx = min((i + 1) * batch_size, len(data))\n",
    "        batch_data = data[start_idx:end_idx]\n",
    "        batch_predictions = encoder.predict(batch_data)\n",
    "        predictions.append(batch_predictions)\n",
    "\n",
    "    return np.concatenate(predictions, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:24:01.281366Z",
     "iopub.status.busy": "2023-05-06T22:24:01.280659Z",
     "iopub.status.idle": "2023-05-06T22:24:01.298728Z",
     "shell.execute_reply": "2023-05-06T22:24:01.297367Z",
     "shell.execute_reply.started": "2023-05-06T22:24:01.281315Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(data_path, sample_percent=0.1, batch_size=8, epochs = 2):\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    # Load the data\n",
    "    train_images, train_labels, val_images, val_labels, age_encoder, gender_encoder, race_encoder = load_sample_data(\n",
    "        data_path, input_shape, \"train.csv\", \"val.csv\", sample_percent=sample_percent\n",
    "    )\n",
    "\n",
    "    # Create the autoencoder model\n",
    "    autoencoder = create_autoencoder(input_shape)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(\n",
    "        train_images, train_images,\n",
    "        epochs=epochs,\n",
    "        batch_size=batch_size,\n",
    "        validation_data=(val_images, val_images)\n",
    "    )\n",
    "\n",
    "    # Extract the encoder\n",
    "    encoder = extract_encoder(autoencoder)\n",
    "\n",
    "    # Encode the train and validation images\n",
    "    train_embeddings = predict_in_batches(encoder, train_images, batch_size)\n",
    "    val_embeddings = predict_in_batches(encoder, val_images, batch_size)\n",
    "\n",
    "\n",
    "    # Flatten the embeddings\n",
    "    train_embeddings = train_embeddings.reshape(train_embeddings.shape[0], -1)\n",
    "    val_embeddings = val_embeddings.reshape(val_embeddings.shape[0], -1)\n",
    "\n",
    "    # Train a classifier on the embeddings\n",
    "    clf = RandomForestClassifier()\n",
    "    clf.fit(train_embeddings, train_labels)\n",
    "\n",
    "    # Predict the labels for the validation set\n",
    "    val_predictions = clf.predict(val_embeddings)\n",
    "\n",
    "    # Compute the accuracy for each attribute\n",
    "    print(\"Validation accuracy:\")\n",
    "    age_metrics = classification_report(val_labels[:, 0], val_predictions[:, 0], target_names=age_encoder.classes_, zero_division=1)\n",
    "    gender_metrics = classification_report(val_labels[:, 1], val_predictions[:, 1], target_names=gender_encoder.classes_, zero_division=1)\n",
    "    race_metrics = classification_report(val_labels[:, 2], val_predictions[:, 2], target_names=race_encoder.classes_, zero_division=1)\n",
    "    print(f\"Age: {age_metrics}\")\n",
    "    print(f\"Gender: {gender_metrics}\")\n",
    "    print(f\"Race: {race_metrics}\")\n",
    "\n",
    "    return {'age_accuracy': age_metrics,\n",
    "            'gender_metrics': gender_metrics,\n",
    "            'race_metrics': race_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T20:29:26.377263Z",
     "iopub.status.busy": "2023-05-06T20:29:26.376580Z",
     "iopub.status.idle": "2023-05-06T20:48:51.195986Z",
     "shell.execute_reply": "2023-05-06T20:48:51.195008Z",
     "shell.execute_reply.started": "2023-05-06T20:29:26.377209Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 16:29:36.983641: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 33409 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:51:00.0, compute capability: 8.6\n",
      "2023-05-06 16:29:46.899523: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-05-06 16:29:47.561690: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-06 16:29:48.056103: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f3abeef3330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-06 16:29:48.056128: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2023-05-06 16:29:48.060811: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-06 16:29:48.132461: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-06 16:29:48.191750: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "data_path = \"./fairface-img-margin025-trainval/fairface-img-margin025-trainval/\"\n",
    "rf_metrics = run_model(data_path, sample_percent = 0.1, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T20:48:51.197453Z",
     "iopub.status.busy": "2023-05-06T20:48:51.197252Z",
     "iopub.status.idle": "2023-05-06T20:48:51.203890Z",
     "shell.execute_reply": "2023-05-06T20:48:51.202954Z",
     "shell.execute_reply.started": "2023-05-06T20:48:51.197435Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('baseline_rf.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T21:00:22.743926Z",
     "iopub.status.busy": "2023-05-06T21:00:22.743563Z",
     "iopub.status.idle": "2023-05-06T21:00:22.749604Z",
     "shell.execute_reply": "2023-05-06T21:00:22.748268Z",
     "shell.execute_reply.started": "2023-05-06T21:00:22.743905Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rf_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrf_metrics\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(rf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgender_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(rf_metrics[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace_metrics\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rf_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "print(rf_metrics['age_accuracy'])\n",
    "print(rf_metrics['gender_metrics'])\n",
    "print(rf_metrics['race_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T20:29:03.244733Z",
     "iopub.status.busy": "2023-05-06T20:29:03.243449Z",
     "iopub.status.idle": "2023-05-06T20:29:03.250445Z",
     "shell.execute_reply": "2023-05-06T20:29:03.249040Z",
     "shell.execute_reply.started": "2023-05-06T20:29:03.244678Z"
    }
   },
   "outputs": [],
   "source": [
    "# rf_metrics_10_epochs = rf_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T21:05:40.813205Z",
     "iopub.status.busy": "2023-05-06T21:05:40.812246Z",
     "iopub.status.idle": "2023-05-06T21:05:41.504582Z",
     "shell.execute_reply": "2023-05-06T21:05:41.502814Z",
     "shell.execute_reply.started": "2023-05-06T21:05:40.813149Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat May  6 17:05:41 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA A40          Off  | 00000000:51:00.0 Off |                    0 |\n",
      "|  0%   50C    P0    83W / 300W |  27676MiB / 46068MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A    900219      C   /usr/bin/python3                10073MiB |\n",
      "|    0   N/A  N/A   1014375      C   /usr/bin/python3                17601MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-05T22:55:04.457219Z",
     "iopub.status.busy": "2023-05-05T22:55:04.455774Z",
     "iopub.status.idle": "2023-05-05T22:55:04.463848Z",
     "shell.execute_reply": "2023-05-05T22:55:04.462410Z",
     "shell.execute_reply.started": "2023-05-05T22:55:04.457158Z"
    }
   },
   "outputs": [],
   "source": [
    "del x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:24:11.024982Z",
     "iopub.status.busy": "2023-05-06T22:24:11.023901Z",
     "iopub.status.idle": "2023-05-06T22:24:11.030297Z",
     "shell.execute_reply": "2023-05-06T22:24:11.028982Z",
     "shell.execute_reply.started": "2023-05-06T22:24:11.024930Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# clear GPU memory\n",
    "tf.compat.v1.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep Learning Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:24:12.951616Z",
     "iopub.status.busy": "2023-05-06T22:24:12.950542Z",
     "iopub.status.idle": "2023-05-06T22:24:12.961589Z",
     "shell.execute_reply": "2023-05-06T22:24:12.960351Z",
     "shell.execute_reply.started": "2023-05-06T22:24:12.951564Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_in_batches_tf(model, data, batch_size):\n",
    "    num_batches = int(np.ceil(len(data) / float(batch_size)))\n",
    "    all_predictions = []\n",
    "\n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(data))\n",
    "        batch_data = data[start_idx:end_idx]\n",
    "        batch_predictions = model.predict(batch_data)\n",
    "        all_predictions.append(batch_predictions)\n",
    "\n",
    "    # Combine the predictions from all batches\n",
    "    combined_predictions = [np.concatenate([batch[i] for batch in all_predictions], axis=0) for i in range(len(all_predictions[0]))]\n",
    "    return combined_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:24:15.049580Z",
     "iopub.status.busy": "2023-05-06T22:24:15.049002Z",
     "iopub.status.idle": "2023-05-06T22:24:15.072071Z",
     "shell.execute_reply": "2023-05-06T22:24:15.070789Z",
     "shell.execute_reply.started": "2023-05-06T22:24:15.049531Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def run_model(data_path, sample_percent=0.1, epochs = 2, encoder_bs = 4, prediction_batch_size=4):\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    # Load the data\n",
    "    train_images, train_labels, val_images, val_labels, age_encoder, gender_encoder, race_encoder = load_sample_data(\n",
    "        data_path, input_shape, \"train.csv\", \"val.csv\", sample_percent=sample_percent\n",
    "    )\n",
    "\n",
    "    num_race_classes = len(race_encoder.classes_)\n",
    "    num_age_classes = len(age_encoder.classes_)\n",
    "    num_gender_classes = len(gender_encoder.classes_)\n",
    "\n",
    "    # Create the autoencoder model\n",
    "    autoencoder = create_autoencoder(input_shape)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(\n",
    "        train_images, train_images,\n",
    "        epochs=epochs,\n",
    "        batch_size=encoder_bs,\n",
    "        validation_data=(val_images, val_images)\n",
    "    )\n",
    "\n",
    "    # Extract the encoder\n",
    "    encoder = extract_encoder(autoencoder)\n",
    "\n",
    "    num_race_classes = len(race_encoder.classes_)\n",
    "    num_age_classes = len(age_encoder.classes_)\n",
    "    num_gender_classes = len(gender_encoder.classes_)\n",
    "\n",
    "    # Create the classification model\n",
    "    classification_model = create_classification_model(encoder, num_race_classes, num_age_classes, num_gender_classes)\n",
    "\n",
    "    # Compile the classification model\n",
    "    classification_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss={\n",
    "            'race_output': SparseCategoricalCrossentropy(),\n",
    "            'age_output': SparseCategoricalCrossentropy(),\n",
    "            'gender_output': SparseCategoricalCrossentropy()\n",
    "        },\n",
    "        metrics={\n",
    "            'race_output': SparseCategoricalAccuracy(),\n",
    "            'age_output': SparseCategoricalAccuracy(),\n",
    "            'gender_output': SparseCategoricalAccuracy()\n",
    "        }\n",
    "    )\n",
    "\n",
    "    # Train the classification model\n",
    "    classification_model.fit(\n",
    "        train_images, [train_labels[:, 2], train_labels[:, 0], train_labels[:, 1]],\n",
    "        epochs=epochs,\n",
    "        batch_size=prediction_batch_size,\n",
    "        validation_data=(val_images, [val_labels[:, 2], val_labels[:, 0], val_labels[:, 1]])\n",
    "    )\n",
    "\n",
    "    # Predict the labels for the validation set\n",
    "    #race_predictions, age_predictions, gender_predictions = classification_model.predict(val_images)\n",
    "\n",
    "    race_predictions, age_predictions, gender_predictions = predict_in_batches_tf(classification_model, \n",
    "                                                                                  val_images, batch_size=prediction_batch_size)\n",
    "\n",
    "\n",
    "    # Compute the accuracy for each attribute\n",
    "    race_metrics = classification_report(val_labels[:, 2], race_predictions.argmax(axis=1), target_names=race_encoder.classes_, zero_division=1)\n",
    "    age_metrics = classification_report(val_labels[:, 0], age_predictions.argmax(axis=1), target_names=age_encoder.classes_, zero_division=1)\n",
    "    gender_metrics = classification_report(val_labels[:, 1], gender_predictions.argmax(axis=1), target_names=gender_encoder.classes_, zero_division=1)\n",
    "\n",
    "    print(\"Validation accuracy:\")\n",
    "\n",
    "    print(f\"Age: {age_metrics}\")\n",
    "    print(f\"Gender: {gender_metrics}\")\n",
    "    print(f\"Race: {race_metrics}\")\n",
    "\n",
    "    return {'age_metrics': age_metrics,\n",
    "            'gender_metrics': gender_metrics,\n",
    "            'race_metrics': race_metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T22:24:18.337620Z",
     "iopub.status.busy": "2023-05-06T22:24:18.336573Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 18:24:32.735952: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43482 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:51:00.0, compute capability: 8.6\n",
      "2023-05-06 18:24:45.618146: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-05-06 18:24:46.277658: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-06 18:24:46.654330: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f2275284b30 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-06 18:24:46.654350: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2023-05-06 18:24:46.658701: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-06 18:24:46.729885: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-06 18:24:46.789480: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "%%capture cap --no-stderr\n",
    "data_path = \"./fairface-img-margin025-trainval/fairface-img-margin025-trainval\"\n",
    "classif_results = run_model(data_path, sample_percent = 0.15, epochs = 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T17:52:17.197131Z",
     "iopub.status.busy": "2023-05-07T17:52:17.195919Z",
     "iopub.status.idle": "2023-05-07T17:52:17.259456Z",
     "shell.execute_reply": "2023-05-07T17:52:17.258456Z",
     "shell.execute_reply.started": "2023-05-07T17:52:17.197078Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('classif.txt', 'w') as f:\n",
    "    f.write(cap.stdout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-07T18:01:40.373032Z",
     "iopub.status.busy": "2023-05-07T18:01:40.371744Z",
     "iopub.status.idle": "2023-05-07T18:01:40.380398Z",
     "shell.execute_reply": "2023-05-07T18:01:40.379100Z",
     "shell.execute_reply.started": "2023-05-07T18:01:40.372974Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0-2       0.40      0.17      0.24        35\n",
      "       10-19       0.19      0.20      0.20       166\n",
      "       20-29       0.37      0.41      0.39       496\n",
      "         3-9       0.45      0.47      0.46       230\n",
      "       30-39       0.25      0.34      0.29       323\n",
      "       40-49       0.19      0.12      0.15       207\n",
      "       50-59       0.23      0.11      0.15       120\n",
      "       60-69       0.00      0.00      0.00        55\n",
      "more than 70       0.00      0.00      0.00        11\n",
      "\n",
      "    accuracy                           0.30      1643\n",
      "   macro avg       0.23      0.20      0.21      1643\n",
      "weighted avg       0.29      0.30      0.29      1643\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "      Female       0.69      0.64      0.67       764\n",
      "        Male       0.71      0.75      0.73       879\n",
      "\n",
      "    accuracy                           0.70      1643\n",
      "   macro avg       0.70      0.70      0.70      1643\n",
      "weighted avg       0.70      0.70      0.70      1643\n",
      "\n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "          Black       0.37      0.55      0.44       239\n",
      "     East Asian       0.43      0.37      0.40       235\n",
      "         Indian       0.30      0.24      0.27       225\n",
      "Latino_Hispanic       0.20      0.15      0.17       232\n",
      " Middle Eastern       0.21      0.26      0.24       187\n",
      "Southeast Asian       0.26      0.21      0.23       212\n",
      "          White       0.33      0.35      0.34       313\n",
      "\n",
      "       accuracy                           0.31      1643\n",
      "      macro avg       0.30      0.30      0.30      1643\n",
      "   weighted avg       0.31      0.31      0.30      1643\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classif_results['age_metrics'])\n",
    "print(classif_results['gender_metrics'])\n",
    "print(classif_results['race_metrics'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to restrict memory consumption\n",
    "We kept getting extensive errors thus had to drop this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T19:33:25.536828Z",
     "iopub.status.busy": "2023-05-06T19:33:25.536051Z",
     "iopub.status.idle": "2023-05-06T19:33:25.545267Z",
     "shell.execute_reply": "2023-05-06T19:33:25.543909Z",
     "shell.execute_reply.started": "2023-05-06T19:33:25.536780Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this function is to use data generators instead of actual images. Hopefully, this will require less\n",
    "# memory to run the code.\n",
    "def load_sample_data(path, input_shape, train_csv, val_csv, sample_percent=0.1):\n",
    "    # Load the dataframes and label encoders\n",
    "    train_df, val_df, age_encoder, gender_encoder, race_encoder = load_labels_and_dataframe(path, \n",
    "                                                                                            \"fairface_label_\"+train_csv, \n",
    "                                                                                            \"fairface_label_\"+val_csv)\n",
    "\n",
    "    # Take a fraction of the dataset\n",
    "    train_df = train_df.sample(frac=sample_percent)\n",
    "    val_df = val_df.sample(frac=sample_percent)\n",
    "\n",
    "    return train_df, val_df, age_encoder, gender_encoder, race_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T19:33:26.731804Z",
     "iopub.status.busy": "2023-05-06T19:33:26.730887Z",
     "iopub.status.idle": "2023-05-06T19:33:26.740062Z",
     "shell.execute_reply": "2023-05-06T19:33:26.738792Z",
     "shell.execute_reply.started": "2023-05-06T19:33:26.731754Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_generator(df, path, input_shape, batch_size):\n",
    "    for i in range(0, len(df), batch_size):\n",
    "        batch_df = df.iloc[i:i+batch_size]\n",
    "        batch_images = load_images(batch_df, path, input_shape)\n",
    "        batch_labels = batch_df[[\"age\", \"gender\", \"race\"]].values\n",
    "        yield batch_images, [batch_labels[:, 2], batch_labels[:, 0], batch_labels[:, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T19:36:36.526506Z",
     "iopub.status.busy": "2023-05-06T19:36:36.526262Z",
     "iopub.status.idle": "2023-05-06T19:36:36.531472Z",
     "shell.execute_reply": "2023-05-06T19:36:36.530535Z",
     "shell.execute_reply.started": "2023-05-06T19:36:36.526487Z"
    }
   },
   "outputs": [],
   "source": [
    "def autoencoder_data_generator(df, data_path, input_shape, batch_size):\n",
    "    while True:\n",
    "        for i in range(0, len(df), batch_size):\n",
    "            batch_df = df.iloc[i:i+batch_size]\n",
    "            batch_images = load_images(batch_df, data_path, input_shape)\n",
    "            yield batch_images, batch_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T19:53:23.153267Z",
     "iopub.status.busy": "2023-05-06T19:53:23.152864Z",
     "iopub.status.idle": "2023-05-06T19:53:23.167363Z",
     "shell.execute_reply": "2023-05-06T19:53:23.166130Z",
     "shell.execute_reply.started": "2023-05-06T19:53:23.153247Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tensorflow.data import Dataset\n",
    "def run_model(data_path, sample_percent=0.1, epochs=2, encoder_bs=4, prediction_batch_size=4):\n",
    "    input_shape = (224, 224, 3)\n",
    "\n",
    "    autoencoder_train_dataset = Dataset.from_generator(\n",
    "        lambda: autoencoder_data_generator(train_df, data_path, input_shape, encoder_bs),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    autoencoder_val_dataset = Dataset.from_generator(\n",
    "        lambda: autoencoder_data_generator(val_df, data_path, input_shape, encoder_bs),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Load the data\n",
    "    \n",
    "    train_df, val_df, age_encoder, gender_encoder, race_encoder = load_sample_data(\n",
    "        data_path, input_shape, \"train.csv\", \"val.csv\", sample_percent=sample_percent\n",
    "    )\n",
    "\n",
    "    num_race_classes = len(race_encoder.classes_)\n",
    "    num_age_classes = len(age_encoder.classes_)\n",
    "    num_gender_classes = len(gender_encoder.classes_)\n",
    "\n",
    "    \n",
    "    # Create the autoencoder model\n",
    "    autoencoder = create_autoencoder(input_shape)\n",
    "    autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "    # Train the autoencoder\n",
    "    autoencoder.fit(\n",
    "        autoencoder_train_dataset,\n",
    "        epochs=2,\n",
    "        steps_per_epoch=len(train_df) // encoder_bs,\n",
    "        validation_data=autoencoder_val_dataset,\n",
    "        validation_steps=len(val_df) // encoder_bs\n",
    "    )\n",
    "    # Extract the encoder\n",
    "    encoder = extract_encoder(autoencoder)\n",
    "\n",
    "    # Create the classification model\n",
    "    classification_model = create_classification_model(encoder, num_race_classes, num_age_classes, num_gender_classes)\n",
    "\n",
    "    # Compile the classification model\n",
    "    classification_model.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss={\n",
    "            'race_output': SparseCategoricalCrossentropy(),\n",
    "            'age_output': SparseCategoricalCrossentropy(),\n",
    "            'gender_output': SparseCategoricalCrossentropy()\n",
    "        },\n",
    "        metrics={\n",
    "            'race_output': SparseCategoricalAccuracy(),\n",
    "            'age_output': SparseCategoricalAccuracy(),\n",
    "            'gender_output': SparseCategoricalAccuracy()\n",
    "        }\n",
    "    )\n",
    "\n",
    "    train_dataset = Dataset.from_generator(\n",
    "        lambda: data_generator(train_df, data_path, input_shape, prediction_batch_size),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "            (\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "    val_dataset = Dataset.from_generator(\n",
    "        lambda: data_generator(val_df, data_path, input_shape, prediction_batch_size),\n",
    "        output_signature=(\n",
    "            tf.TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32),\n",
    "            (\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32),\n",
    "                tf.TensorSpec(shape=(None,), dtype=tf.int32)\n",
    "            )\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    # Train the classification model\n",
    "    classification_model.fit(\n",
    "        train_dataset,\n",
    "        epochs=epochs,\n",
    "        steps_per_epoch=len(train_df) // prediction_batch_size,\n",
    "        validation_data=val_dataset,\n",
    "        validation_steps=len(val_df) // prediction_batch_size\n",
    "    )\n",
    "\n",
    "    # Predict the labels for the validation set\n",
    "    race_predictions, age_predictions, gender_predictions = predict_in_batches_tf(classification_model, \n",
    "                                                                                  val_images, batch_size=prediction_batch_size)\n",
    "\n",
    "    # Compute the accuracy for each attribute\n",
    "    print(\"Validation accuracy:\")\n",
    "    print(\"Race:\")\n",
    "    print(classification_report(val_labels[:, 2], race_predictions.argmax(axis=1), target_names=race_encoder.classes_, zero_division=1))\n",
    "    print(\"Age:\")\n",
    "    print(classification_report(val_labels[:, 0], age_predictions.argmax(axis=1), target_names=age_encoder.classes_, zero_division=1))\n",
    "    print(\"Gender:\")\n",
    "    print(classification_report(val_labels[:, 1], gender_predictions.argmax(axis=1), target_names=gender_encoder.classes_, zero_division=1))\n",
    "    \n",
    "    return encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-06T19:53:24.125539Z",
     "iopub.status.busy": "2023-05-06T19:53:24.124567Z",
     "iopub.status.idle": "2023-05-06T19:54:58.400042Z",
     "shell.execute_reply": "2023-05-06T19:54:58.397815Z",
     "shell.execute_reply.started": "2023-05-06T19:53:24.125490Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:53:24.396061: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4335/4337 [============================>.] - ETA: 0s - loss: 0.0016"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:54:08.375280: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4337/4337 [==============================] - 46s 10ms/step - loss: 0.0016 - val_loss: 6.8946e-04\n",
      "Epoch 2/2\n",
      "4337/4337 [==============================] - 45s 10ms/step - loss: 7.2530e-04 - val_loss: 6.1968e-04\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-06 15:54:55.862036: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2023-05-06 15:54:57.071306: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n",
      "    assert_shallow_structure(shallow_branch, input_branch,\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "\n",
      "\n",
      "2023-05-06 15:54:57.071406: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n",
      "    assert_shallow_structure(shallow_branch, input_branch,\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "2023-05-06 15:54:57.071597: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n",
      "    assert_shallow_structure(shallow_branch, input_branch,\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "     "
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n         [0.41568628, 0.38039216, 0.3529412 ],\n         [0.39607844, 0.36862746, 0.3372549 ],\n         ...,\n         [0.89411765, 0.92941177, 0.5647059 ],\n         [0.8980392 , 0.92941177, 0.5411765 ],\n         [0.8901961 , 0.92156863, 0.5254902 ]],\n\n        [[0.45490196, 0.41960785, 0.39215687],\n         [0.41960785, 0.38431373, 0.35686275],\n         [0.40392157, 0.3764706 , 0.34509805],\n         ...,\n         [0.9137255 , 0.9372549 , 0.5921569 ],\n         [0.9019608 , 0.92941177, 0.5647059 ],\n         [0.8901961 , 0.91764706, 0.54509807]],\n\n        [[0.4117647 , 0.3764706 , 0.34901962],\n         [0.40392157, 0.36862746, 0.34117648],\n         [0.40784314, 0.38039216, 0.34901962],\n         ...,\n         [0.92941177, 0.9372549 , 0.6431373 ],\n         [0.9137255 , 0.9254902 , 0.6156863 ],\n         [0.8980392 , 0.9137255 , 0.58431375]],\n\n        ...,\n\n        [[0.5568628 , 0.5568628 , 0.54901963],\n         [0.52156866, 0.52156866, 0.5137255 ],\n         [0.46666667, 0.46666667, 0.45882353],\n         ...,\n         [0.1882353 , 0.20392157, 0.2       ],\n         [0.19215687, 0.20784314, 0.20392157],\n         [0.19215687, 0.20784314, 0.20392157]],\n\n        [[0.56078434, 0.56078434, 0.5529412 ],\n         [0.5294118 , 0.5294118 , 0.52156866],\n         [0.4745098 , 0.4745098 , 0.46666667],\n         ...,\n         [0.19215687, 0.20784314, 0.20392157],\n         [0.19607843, 0.21176471, 0.20784314],\n         [0.19607843, 0.21176471, 0.20784314]],\n\n        [[0.57254905, 0.57254905, 0.5647059 ],\n         [0.5411765 , 0.5411765 , 0.53333336],\n         [0.48235294, 0.48235294, 0.4745098 ],\n         ...,\n         [0.19607843, 0.21176471, 0.20784314],\n         [0.2       , 0.21568628, 0.21176471],\n         [0.2       , 0.21568628, 0.21176471]]],\n\n\n       [[[0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         ...,\n         [0.7882353 , 0.6431373 , 0.5411765 ],\n         [0.78039217, 0.63529414, 0.53333336],\n         [0.78039217, 0.63529414, 0.53333336]],\n\n        [[0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         ...,\n         [0.7882353 , 0.6431373 , 0.5411765 ],\n         [0.78431374, 0.6392157 , 0.5372549 ],\n         [0.78039217, 0.63529414, 0.53333336]],\n\n        [[0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         ...,\n         [0.7921569 , 0.64705884, 0.54509807],\n         [0.7882353 , 0.6431373 , 0.5411765 ],\n         [0.78431374, 0.6392157 , 0.5372549 ]],\n\n        ...,\n\n        [[0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         ...,\n         [0.90588236, 0.88235295, 0.8901961 ],\n         [0.8980392 , 0.8745098 , 0.88235295],\n         [0.89411765, 0.87058824, 0.8784314 ]],\n\n        [[0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         ...,\n         [0.9019608 , 0.8784314 , 0.8862745 ],\n         [0.89411765, 0.87058824, 0.8784314 ],\n         [0.8901961 , 0.8666667 , 0.8745098 ]],\n\n        [[0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         ...,\n         [0.8980392 , 0.8745098 , 0.88235295],\n         [0.89411765, 0.87058824, 0.8784314 ],\n         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n\n\n       [[[0.20784314, 0.21176471, 0.19215687],\n         [0.19607843, 0.2       , 0.18039216],\n         [0.18039216, 0.18431373, 0.16470589],\n         ...,\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138]],\n\n        [[0.22745098, 0.23137255, 0.21176471],\n         [0.21960784, 0.22352941, 0.20392157],\n         [0.20784314, 0.21176471, 0.19215687],\n         ...,\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138]],\n\n        [[0.25490198, 0.25882354, 0.23921569],\n         [0.2509804 , 0.25490198, 0.23529412],\n         [0.23921569, 0.24313726, 0.22352941],\n         ...,\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138]],\n\n        ...,\n\n        [[0.9607843 , 0.9647059 , 0.9098039 ],\n         [0.9607843 , 0.9647059 , 0.9098039 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         ...,\n         [0.47058824, 0.42352942, 0.3372549 ],\n         [0.4627451 , 0.4117647 , 0.3372549 ],\n         [0.45490196, 0.40392157, 0.32941177]],\n\n        [[0.9647059 , 0.96862745, 0.9137255 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         ...,\n         [0.4862745 , 0.42745098, 0.34509805],\n         [0.4862745 , 0.42745098, 0.3529412 ],\n         [0.49019608, 0.43137255, 0.35686275]],\n\n        [[0.9647059 , 0.96862745, 0.9137255 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         [0.96862745, 0.972549  , 0.91764706],\n         ...,\n         [0.49019608, 0.43137255, 0.34901962],\n         [0.5019608 , 0.44313726, 0.36862746],\n         [0.50980395, 0.4509804 , 0.3764706 ]]],\n\n\n       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n         [0.5058824 , 0.5058824 , 0.5058824 ],\n         [0.50980395, 0.50980395, 0.50980395],\n         ...,\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ]],\n\n        [[0.50980395, 0.50980395, 0.50980395],\n         [0.50980395, 0.50980395, 0.50980395],\n         [0.5137255 , 0.5137255 , 0.5137255 ],\n         ...,\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ]],\n\n        [[0.5176471 , 0.5176471 , 0.5176471 ],\n         [0.52156866, 0.52156866, 0.52156866],\n         [0.52156866, 0.52156866, 0.52156866],\n         ...,\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ]],\n\n        ...,\n\n        [[0.48235294, 0.48235294, 0.48235294],\n         [0.4745098 , 0.4745098 , 0.4745098 ],\n         [0.47058824, 0.47058824, 0.47058824],\n         ...,\n         [0.5372549 , 0.5372549 , 0.5372549 ],\n         [0.4       , 0.4       , 0.4       ],\n         [0.2509804 , 0.2509804 , 0.2509804 ]],\n\n        [[0.4745098 , 0.4745098 , 0.4745098 ],\n         [0.46666667, 0.46666667, 0.46666667],\n         [0.45882353, 0.45882353, 0.45882353],\n         ...,\n         [0.49803922, 0.49803922, 0.49803922],\n         [0.36078432, 0.36078432, 0.36078432],\n         [0.21568628, 0.21568628, 0.21568628]],\n\n        [[0.49019608, 0.49019608, 0.49019608],\n         [0.47843137, 0.47843137, 0.47843137],\n         [0.47058824, 0.47058824, 0.47058824],\n         ...,\n         [0.47058824, 0.47058824, 0.47058824],\n         [0.32941177, 0.32941177, 0.32941177],\n         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\nTraceback (most recent call last):\n\n  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n [Op:__inference_train_function_67317]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m data_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./fairface-img-margin025-trainval/fairface-img-margin025-trainval\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_percent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36mrun_model\u001b[0;34m(data_path, sample_percent, epochs, encoder_bs, prediction_batch_size)\u001b[0m\n\u001b[1;32m     77\u001b[0m val_dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_generator(\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m: data_generator(val_df, data_path, input_shape, prediction_batch_size),\n\u001b[1;32m     79\u001b[0m     output_signature\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     )\n\u001b[1;32m     87\u001b[0m )\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m# Train the classification model\u001b[39;00m\n\u001b[0;32m---> 91\u001b[0m \u001b[43mclassification_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprediction_batch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     96\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mprediction_batch_size\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;66;03m# Predict the labels for the validation set\u001b[39;00m\n\u001b[1;32m    100\u001b[0m race_predictions, age_predictions, gender_predictions \u001b[38;5;241m=\u001b[39m predict_in_batches_tf(classification_model, \n\u001b[1;32m    101\u001b[0m                                                                               val_images, batch_size\u001b[38;5;241m=\u001b[39mprediction_batch_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     51\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 52\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     55\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n         [0.41568628, 0.38039216, 0.3529412 ],\n         [0.39607844, 0.36862746, 0.3372549 ],\n         ...,\n         [0.89411765, 0.92941177, 0.5647059 ],\n         [0.8980392 , 0.92941177, 0.5411765 ],\n         [0.8901961 , 0.92156863, 0.5254902 ]],\n\n        [[0.45490196, 0.41960785, 0.39215687],\n         [0.41960785, 0.38431373, 0.35686275],\n         [0.40392157, 0.3764706 , 0.34509805],\n         ...,\n         [0.9137255 , 0.9372549 , 0.5921569 ],\n         [0.9019608 , 0.92941177, 0.5647059 ],\n         [0.8901961 , 0.91764706, 0.54509807]],\n\n        [[0.4117647 , 0.3764706 , 0.34901962],\n         [0.40392157, 0.36862746, 0.34117648],\n         [0.40784314, 0.38039216, 0.34901962],\n         ...,\n         [0.92941177, 0.9372549 , 0.6431373 ],\n         [0.9137255 , 0.9254902 , 0.6156863 ],\n         [0.8980392 , 0.9137255 , 0.58431375]],\n\n        ...,\n\n        [[0.5568628 , 0.5568628 , 0.54901963],\n         [0.52156866, 0.52156866, 0.5137255 ],\n         [0.46666667, 0.46666667, 0.45882353],\n         ...,\n         [0.1882353 , 0.20392157, 0.2       ],\n         [0.19215687, 0.20784314, 0.20392157],\n         [0.19215687, 0.20784314, 0.20392157]],\n\n        [[0.56078434, 0.56078434, 0.5529412 ],\n         [0.5294118 , 0.5294118 , 0.52156866],\n         [0.4745098 , 0.4745098 , 0.46666667],\n         ...,\n         [0.19215687, 0.20784314, 0.20392157],\n         [0.19607843, 0.21176471, 0.20784314],\n         [0.19607843, 0.21176471, 0.20784314]],\n\n        [[0.57254905, 0.57254905, 0.5647059 ],\n         [0.5411765 , 0.5411765 , 0.53333336],\n         [0.48235294, 0.48235294, 0.4745098 ],\n         ...,\n         [0.19607843, 0.21176471, 0.20784314],\n         [0.2       , 0.21568628, 0.21176471],\n         [0.2       , 0.21568628, 0.21176471]]],\n\n\n       [[[0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         ...,\n         [0.7882353 , 0.6431373 , 0.5411765 ],\n         [0.78039217, 0.63529414, 0.53333336],\n         [0.78039217, 0.63529414, 0.53333336]],\n\n        [[0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         ...,\n         [0.7882353 , 0.6431373 , 0.5411765 ],\n         [0.78431374, 0.6392157 , 0.5372549 ],\n         [0.78039217, 0.63529414, 0.53333336]],\n\n        [[0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         [0.12941177, 0.13725491, 0.11764706],\n         ...,\n         [0.7921569 , 0.64705884, 0.54509807],\n         [0.7882353 , 0.6431373 , 0.5411765 ],\n         [0.78431374, 0.6392157 , 0.5372549 ]],\n\n        ...,\n\n        [[0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         ...,\n         [0.90588236, 0.88235295, 0.8901961 ],\n         [0.8980392 , 0.8745098 , 0.88235295],\n         [0.89411765, 0.87058824, 0.8784314 ]],\n\n        [[0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         ...,\n         [0.9019608 , 0.8784314 , 0.8862745 ],\n         [0.89411765, 0.87058824, 0.8784314 ],\n         [0.8901961 , 0.8666667 , 0.8745098 ]],\n\n        [[0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         [0.10980392, 0.10196079, 0.14509805],\n         ...,\n         [0.8980392 , 0.8745098 , 0.88235295],\n         [0.89411765, 0.87058824, 0.8784314 ],\n         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n\n\n       [[[0.20784314, 0.21176471, 0.19215687],\n         [0.19607843, 0.2       , 0.18039216],\n         [0.18039216, 0.18431373, 0.16470589],\n         ...,\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138]],\n\n        [[0.22745098, 0.23137255, 0.21176471],\n         [0.21960784, 0.22352941, 0.20392157],\n         [0.20784314, 0.21176471, 0.19215687],\n         ...,\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138]],\n\n        [[0.25490198, 0.25882354, 0.23921569],\n         [0.2509804 , 0.25490198, 0.23529412],\n         [0.23921569, 0.24313726, 0.22352941],\n         ...,\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138],\n         [0.10588235, 0.09019608, 0.07843138]],\n\n        ...,\n\n        [[0.9607843 , 0.9647059 , 0.9098039 ],\n         [0.9607843 , 0.9647059 , 0.9098039 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         ...,\n         [0.47058824, 0.42352942, 0.3372549 ],\n         [0.4627451 , 0.4117647 , 0.3372549 ],\n         [0.45490196, 0.40392157, 0.32941177]],\n\n        [[0.9647059 , 0.96862745, 0.9137255 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         ...,\n         [0.4862745 , 0.42745098, 0.34509805],\n         [0.4862745 , 0.42745098, 0.3529412 ],\n         [0.49019608, 0.43137255, 0.35686275]],\n\n        [[0.9647059 , 0.96862745, 0.9137255 ],\n         [0.9647059 , 0.96862745, 0.9137255 ],\n         [0.96862745, 0.972549  , 0.91764706],\n         ...,\n         [0.49019608, 0.43137255, 0.34901962],\n         [0.5019608 , 0.44313726, 0.36862746],\n         [0.50980395, 0.4509804 , 0.3764706 ]]],\n\n\n       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n         [0.5058824 , 0.5058824 , 0.5058824 ],\n         [0.50980395, 0.50980395, 0.50980395],\n         ...,\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ]],\n\n        [[0.50980395, 0.50980395, 0.50980395],\n         [0.50980395, 0.50980395, 0.50980395],\n         [0.5137255 , 0.5137255 , 0.5137255 ],\n         ...,\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ]],\n\n        [[0.5176471 , 0.5176471 , 0.5176471 ],\n         [0.52156866, 0.52156866, 0.52156866],\n         [0.52156866, 0.52156866, 0.52156866],\n         ...,\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9098039 , 0.9098039 , 0.9098039 ],\n         [0.9137255 , 0.9137255 , 0.9137255 ]],\n\n        ...,\n\n        [[0.48235294, 0.48235294, 0.48235294],\n         [0.4745098 , 0.4745098 , 0.4745098 ],\n         [0.47058824, 0.47058824, 0.47058824],\n         ...,\n         [0.5372549 , 0.5372549 , 0.5372549 ],\n         [0.4       , 0.4       , 0.4       ],\n         [0.2509804 , 0.2509804 , 0.2509804 ]],\n\n        [[0.4745098 , 0.4745098 , 0.4745098 ],\n         [0.46666667, 0.46666667, 0.46666667],\n         [0.45882353, 0.45882353, 0.45882353],\n         ...,\n         [0.49803922, 0.49803922, 0.49803922],\n         [0.36078432, 0.36078432, 0.36078432],\n         [0.21568628, 0.21568628, 0.21568628]],\n\n        [[0.49019608, 0.49019608, 0.49019608],\n         [0.47843137, 0.47843137, 0.47843137],\n         [0.47058824, 0.47058824, 0.47058824],\n         ...,\n         [0.47058824, 0.47058824, 0.47058824],\n         [0.32941177, 0.32941177, 0.32941177],\n         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\nTraceback (most recent call last):\n\n  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n    flattened_values = nest.flatten_up_to(output_types, values)\n\n  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n    assert_shallow_structure(shallow_tree, input_tree)\n\n  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n [Op:__inference_train_function_67317]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "2023-05-06 15:54:57.071683: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:GPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n",
      "    assert_shallow_structure(shallow_branch, input_branch,\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.47058824, 0.43529412, 0.40784314],\n",
      "         [0.41568628, 0.38039216, 0.3529412 ],\n",
      "         [0.39607844, 0.36862746, 0.3372549 ],\n",
      "         ...,\n",
      "         [0.89411765, 0.92941177, 0.5647059 ],\n",
      "         [0.8980392 , 0.92941177, 0.5411765 ],\n",
      "         [0.8901961 , 0.92156863, 0.5254902 ]],\n",
      "\n",
      "        [[0.45490196, 0.41960785, 0.39215687],\n",
      "         [0.41960785, 0.38431373, 0.35686275],\n",
      "         [0.40392157, 0.3764706 , 0.34509805],\n",
      "         ...,\n",
      "         [0.9137255 , 0.9372549 , 0.5921569 ],\n",
      "         [0.9019608 , 0.92941177, 0.5647059 ],\n",
      "         [0.8901961 , 0.91764706, 0.54509807]],\n",
      "\n",
      "        [[0.4117647 , 0.3764706 , 0.34901962],\n",
      "         [0.40392157, 0.36862746, 0.34117648],\n",
      "         [0.40784314, 0.38039216, 0.34901962],\n",
      "         ...,\n",
      "         [0.92941177, 0.9372549 , 0.6431373 ],\n",
      "         [0.9137255 , 0.9254902 , 0.6156863 ],\n",
      "         [0.8980392 , 0.9137255 , 0.58431375]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.5568628 , 0.5568628 , 0.54901963],\n",
      "         [0.52156866, 0.52156866, 0.5137255 ],\n",
      "         [0.46666667, 0.46666667, 0.45882353],\n",
      "         ...,\n",
      "         [0.1882353 , 0.20392157, 0.2       ],\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19215687, 0.20784314, 0.20392157]],\n",
      "\n",
      "        [[0.56078434, 0.56078434, 0.5529412 ],\n",
      "         [0.5294118 , 0.5294118 , 0.52156866],\n",
      "         [0.4745098 , 0.4745098 , 0.46666667],\n",
      "         ...,\n",
      "         [0.19215687, 0.20784314, 0.20392157],\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.19607843, 0.21176471, 0.20784314]],\n",
      "\n",
      "        [[0.57254905, 0.57254905, 0.5647059 ],\n",
      "         [0.5411765 , 0.5411765 , 0.53333336],\n",
      "         [0.48235294, 0.48235294, 0.4745098 ],\n",
      "         ...,\n",
      "         [0.19607843, 0.21176471, 0.20784314],\n",
      "         [0.2       , 0.21568628, 0.21176471],\n",
      "         [0.2       , 0.21568628, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ],\n",
      "         [0.78039217, 0.63529414, 0.53333336]],\n",
      "\n",
      "        [[0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         [0.12941177, 0.13725491, 0.11764706],\n",
      "         ...,\n",
      "         [0.7921569 , 0.64705884, 0.54509807],\n",
      "         [0.7882353 , 0.6431373 , 0.5411765 ],\n",
      "         [0.78431374, 0.6392157 , 0.5372549 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.90588236, 0.88235295, 0.8901961 ],\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.9019608 , 0.8784314 , 0.8862745 ],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]],\n",
      "\n",
      "        [[0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         [0.10980392, 0.10196079, 0.14509805],\n",
      "         ...,\n",
      "         [0.8980392 , 0.8745098 , 0.88235295],\n",
      "         [0.89411765, 0.87058824, 0.8784314 ],\n",
      "         [0.8901961 , 0.8666667 , 0.8745098 ]]],\n",
      "\n",
      "\n",
      "       [[[0.20784314, 0.21176471, 0.19215687],\n",
      "         [0.19607843, 0.2       , 0.18039216],\n",
      "         [0.18039216, 0.18431373, 0.16470589],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.22745098, 0.23137255, 0.21176471],\n",
      "         [0.21960784, 0.22352941, 0.20392157],\n",
      "         [0.20784314, 0.21176471, 0.19215687],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        [[0.25490198, 0.25882354, 0.23921569],\n",
      "         [0.2509804 , 0.25490198, 0.23529412],\n",
      "         [0.23921569, 0.24313726, 0.22352941],\n",
      "         ...,\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138],\n",
      "         [0.10588235, 0.09019608, 0.07843138]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9607843 , 0.9647059 , 0.9098039 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.47058824, 0.42352942, 0.3372549 ],\n",
      "         [0.4627451 , 0.4117647 , 0.3372549 ],\n",
      "         [0.45490196, 0.40392157, 0.32941177]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         ...,\n",
      "         [0.4862745 , 0.42745098, 0.34509805],\n",
      "         [0.4862745 , 0.42745098, 0.3529412 ],\n",
      "         [0.49019608, 0.43137255, 0.35686275]],\n",
      "\n",
      "        [[0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.9647059 , 0.96862745, 0.9137255 ],\n",
      "         [0.96862745, 0.972549  , 0.91764706],\n",
      "         ...,\n",
      "         [0.49019608, 0.43137255, 0.34901962],\n",
      "         [0.5019608 , 0.44313726, 0.36862746],\n",
      "         [0.50980395, 0.4509804 , 0.3764706 ]]],\n",
      "\n",
      "\n",
      "       [[[0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.5058824 , 0.5058824 , 0.5058824 ],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.50980395, 0.50980395, 0.50980395],\n",
      "         [0.5137255 , 0.5137255 , 0.5137255 ],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        [[0.5176471 , 0.5176471 , 0.5176471 ],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         [0.52156866, 0.52156866, 0.52156866],\n",
      "         ...,\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9098039 , 0.9098039 , 0.9098039 ],\n",
      "         [0.9137255 , 0.9137255 , 0.9137255 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.48235294, 0.48235294, 0.48235294],\n",
      "         [0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.5372549 , 0.5372549 , 0.5372549 ],\n",
      "         [0.4       , 0.4       , 0.4       ],\n",
      "         [0.2509804 , 0.2509804 , 0.2509804 ]],\n",
      "\n",
      "        [[0.4745098 , 0.4745098 , 0.4745098 ],\n",
      "         [0.46666667, 0.46666667, 0.46666667],\n",
      "         [0.45882353, 0.45882353, 0.45882353],\n",
      "         ...,\n",
      "         [0.49803922, 0.49803922, 0.49803922],\n",
      "         [0.36078432, 0.36078432, 0.36078432],\n",
      "         [0.21568628, 0.21568628, 0.21568628]],\n",
      "\n",
      "        [[0.49019608, 0.49019608, 0.49019608],\n",
      "         [0.47843137, 0.47843137, 0.47843137],\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         ...,\n",
      "         [0.47058824, 0.47058824, 0.47058824],\n",
      "         [0.32941177, 0.32941177, 0.32941177],\n",
      "         [0.18431373, 0.18431373, 0.18431373]]]], dtype=float32), [array([5, 6, 5, 3]), array([7, 0, 2, 2]), array([1, 1, 1, 1])]).\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n",
      "\t [[IteratorGetNext]]\n",
      "\t [[IteratorGetNext/_4]]\n",
      "2023-05-06 15:54:58.411904: W tensorflow/core/framework/op_kernel.cc:1818] INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.41960785, 0.4       , 0.3254902 ],\n",
      "         [0.3882353 , 0.3764706 , 0.30980393],\n",
      "         [0.36862746, 0.35686275, 0.2901961 ]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.42745098, 0.40784314, 0.33333334],\n",
      "         [0.4       , 0.3882353 , 0.32156864],\n",
      "         [0.38431373, 0.37254903, 0.30588236]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.44313726, 0.42352942, 0.34901962],\n",
      "         [0.41568628, 0.40392157, 0.3372549 ],\n",
      "         [0.4       , 0.3882353 , 0.32156864]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.34117648, 0.14117648, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         [0.34509805, 0.14509805, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3372549 , 0.14509805, 0.2627451 ],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3254902 , 0.14509805, 0.25882354],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.33333334, 0.15294118, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.9254902 , 0.7294118 , 0.4509804 ],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92156863, 0.7254902 , 0.44705883],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92941177, 0.72156864, 0.44705883],\n",
      "         [0.9372549 , 0.7294118 , 0.45490196],\n",
      "         [0.9490196 , 0.7411765 , 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]]],\n",
      "\n",
      "\n",
      "       [[[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.627451  , 0.3529412 , 0.44705883],\n",
      "         [0.6313726 , 0.34117648, 0.4392157 ],\n",
      "         [0.62352943, 0.33333334, 0.42352942]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.6431373 , 0.36862746, 0.4627451 ],\n",
      "         [0.6392157 , 0.35686275, 0.4509804 ],\n",
      "         [0.63529414, 0.34509805, 0.43529412]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.654902  , 0.3882353 , 0.47843137],\n",
      "         [0.654902  , 0.37254903, 0.46666667],\n",
      "         [0.6431373 , 0.36078432, 0.44705883]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8039216 , 0.26666668, 0.44705883],\n",
      "         [0.77254903, 0.2509804 , 0.42745098],\n",
      "         [0.7176471 , 0.23529412, 0.40784314],\n",
      "         ...,\n",
      "         [0.53333336, 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668]],\n",
      "\n",
      "        [[0.6627451 , 0.23137255, 0.38431373],\n",
      "         [0.6392157 , 0.22352941, 0.37254903],\n",
      "         [0.6039216 , 0.22352941, 0.36078432],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]],\n",
      "\n",
      "        [[0.5568628 , 0.1764706 , 0.3137255 ],\n",
      "         [0.54901963, 0.18039216, 0.3137255 ],\n",
      "         [0.5372549 , 0.20392157, 0.3254902 ],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]]],\n",
      "\n",
      "\n",
      "       [[[0.8039216 , 0.8117647 , 0.7607843 ],\n",
      "         [0.8117647 , 0.81960785, 0.7647059 ],\n",
      "         [0.827451  , 0.83137256, 0.7764706 ],\n",
      "         ...,\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08627451, 0.09019608, 0.06666667],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.7921569 , 0.8       , 0.7490196 ],\n",
      "         [0.8039216 , 0.8117647 , 0.75686276],\n",
      "         [0.8235294 , 0.827451  , 0.77254903],\n",
      "         ...,\n",
      "         [0.07450981, 0.07843138, 0.05490196],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.78039217, 0.7882353 , 0.7372549 ],\n",
      "         [0.79607844, 0.8039216 , 0.7490196 ],\n",
      "         [0.8156863 , 0.81960785, 0.7647059 ],\n",
      "         ...,\n",
      "         [0.07058824, 0.07450981, 0.05098039],\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.75686276, 0.65882355, 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7372549 , 0.42745098, 0.27450982],\n",
      "         [0.7490196 , 0.4392157 , 0.2784314 ],\n",
      "         [0.75686276, 0.44705883, 0.28627452]],\n",
      "\n",
      "        [[0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7490196 , 0.42745098, 0.2784314 ],\n",
      "         [0.7607843 , 0.4392157 , 0.28235295],\n",
      "         [0.77254903, 0.4509804 , 0.29411766]],\n",
      "\n",
      "        [[0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.75686276, 0.6666667 , 0.5411765 ],\n",
      "         ...,\n",
      "         [0.7529412 , 0.43137255, 0.28235295],\n",
      "         [0.7647059 , 0.44313726, 0.28627452],\n",
      "         [0.7764706 , 0.45490196, 0.29803923]]]], dtype=float32), [array([4, 6, 3, 3]), array([5, 4, 4, 4]), array([1, 1, 1, 0])]).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n",
      "    assert_shallow_structure(shallow_branch, input_branch,\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.41960785, 0.4       , 0.3254902 ],\n",
      "         [0.3882353 , 0.3764706 , 0.30980393],\n",
      "         [0.36862746, 0.35686275, 0.2901961 ]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.42745098, 0.40784314, 0.33333334],\n",
      "         [0.4       , 0.3882353 , 0.32156864],\n",
      "         [0.38431373, 0.37254903, 0.30588236]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.44313726, 0.42352942, 0.34901962],\n",
      "         [0.41568628, 0.40392157, 0.3372549 ],\n",
      "         [0.4       , 0.3882353 , 0.32156864]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.34117648, 0.14117648, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         [0.34509805, 0.14509805, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3372549 , 0.14509805, 0.2627451 ],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3254902 , 0.14509805, 0.25882354],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.33333334, 0.15294118, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.9254902 , 0.7294118 , 0.4509804 ],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92156863, 0.7254902 , 0.44705883],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92941177, 0.72156864, 0.44705883],\n",
      "         [0.9372549 , 0.7294118 , 0.45490196],\n",
      "         [0.9490196 , 0.7411765 , 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]]],\n",
      "\n",
      "\n",
      "       [[[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.627451  , 0.3529412 , 0.44705883],\n",
      "         [0.6313726 , 0.34117648, 0.4392157 ],\n",
      "         [0.62352943, 0.33333334, 0.42352942]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.6431373 , 0.36862746, 0.4627451 ],\n",
      "         [0.6392157 , 0.35686275, 0.4509804 ],\n",
      "         [0.63529414, 0.34509805, 0.43529412]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.654902  , 0.3882353 , 0.47843137],\n",
      "         [0.654902  , 0.37254903, 0.46666667],\n",
      "         [0.6431373 , 0.36078432, 0.44705883]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8039216 , 0.26666668, 0.44705883],\n",
      "         [0.77254903, 0.2509804 , 0.42745098],\n",
      "         [0.7176471 , 0.23529412, 0.40784314],\n",
      "         ...,\n",
      "         [0.53333336, 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668]],\n",
      "\n",
      "        [[0.6627451 , 0.23137255, 0.38431373],\n",
      "         [0.6392157 , 0.22352941, 0.37254903],\n",
      "         [0.6039216 , 0.22352941, 0.36078432],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]],\n",
      "\n",
      "        [[0.5568628 , 0.1764706 , 0.3137255 ],\n",
      "         [0.54901963, 0.18039216, 0.3137255 ],\n",
      "         [0.5372549 , 0.20392157, 0.3254902 ],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]]],\n",
      "\n",
      "\n",
      "       [[[0.8039216 , 0.8117647 , 0.7607843 ],\n",
      "         [0.8117647 , 0.81960785, 0.7647059 ],\n",
      "         [0.827451  , 0.83137256, 0.7764706 ],\n",
      "         ...,\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08627451, 0.09019608, 0.06666667],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.7921569 , 0.8       , 0.7490196 ],\n",
      "         [0.8039216 , 0.8117647 , 0.75686276],\n",
      "         [0.8235294 , 0.827451  , 0.77254903],\n",
      "         ...,\n",
      "         [0.07450981, 0.07843138, 0.05490196],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.78039217, 0.7882353 , 0.7372549 ],\n",
      "         [0.79607844, 0.8039216 , 0.7490196 ],\n",
      "         [0.8156863 , 0.81960785, 0.7647059 ],\n",
      "         ...,\n",
      "         [0.07058824, 0.07450981, 0.05098039],\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.75686276, 0.65882355, 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7372549 , 0.42745098, 0.27450982],\n",
      "         [0.7490196 , 0.4392157 , 0.2784314 ],\n",
      "         [0.75686276, 0.44705883, 0.28627452]],\n",
      "\n",
      "        [[0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7490196 , 0.42745098, 0.2784314 ],\n",
      "         [0.7607843 , 0.4392157 , 0.28235295],\n",
      "         [0.77254903, 0.4509804 , 0.29411766]],\n",
      "\n",
      "        [[0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.75686276, 0.6666667 , 0.5411765 ],\n",
      "         ...,\n",
      "         [0.7529412 , 0.43137255, 0.28235295],\n",
      "         [0.7647059 , 0.44313726, 0.28627452],\n",
      "         [0.7764706 , 0.45490196, 0.29803923]]]], dtype=float32), [array([4, 6, 3, 3]), array([5, 4, 4, 4]), array([1, 1, 1, 0])]).\n",
      "\n",
      "\n",
      "2023-05-06 15:54:58.412012: I tensorflow/core/common_runtime/executor.cc:1197] [/job:localhost/replica:0/task:0/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.41960785, 0.4       , 0.3254902 ],\n",
      "         [0.3882353 , 0.3764706 , 0.30980393],\n",
      "         [0.36862746, 0.35686275, 0.2901961 ]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.42745098, 0.40784314, 0.33333334],\n",
      "         [0.4       , 0.3882353 , 0.32156864],\n",
      "         [0.38431373, 0.37254903, 0.30588236]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.44313726, 0.42352942, 0.34901962],\n",
      "         [0.41568628, 0.40392157, 0.3372549 ],\n",
      "         [0.4       , 0.3882353 , 0.32156864]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.34117648, 0.14117648, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         [0.34509805, 0.14509805, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3372549 , 0.14509805, 0.2627451 ],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3254902 , 0.14509805, 0.25882354],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.33333334, 0.15294118, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.9254902 , 0.7294118 , 0.4509804 ],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92156863, 0.7254902 , 0.44705883],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92941177, 0.72156864, 0.44705883],\n",
      "         [0.9372549 , 0.7294118 , 0.45490196],\n",
      "         [0.9490196 , 0.7411765 , 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]]],\n",
      "\n",
      "\n",
      "       [[[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.627451  , 0.3529412 , 0.44705883],\n",
      "         [0.6313726 , 0.34117648, 0.4392157 ],\n",
      "         [0.62352943, 0.33333334, 0.42352942]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.6431373 , 0.36862746, 0.4627451 ],\n",
      "         [0.6392157 , 0.35686275, 0.4509804 ],\n",
      "         [0.63529414, 0.34509805, 0.43529412]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.654902  , 0.3882353 , 0.47843137],\n",
      "         [0.654902  , 0.37254903, 0.46666667],\n",
      "         [0.6431373 , 0.36078432, 0.44705883]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8039216 , 0.26666668, 0.44705883],\n",
      "         [0.77254903, 0.2509804 , 0.42745098],\n",
      "         [0.7176471 , 0.23529412, 0.40784314],\n",
      "         ...,\n",
      "         [0.53333336, 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668]],\n",
      "\n",
      "        [[0.6627451 , 0.23137255, 0.38431373],\n",
      "         [0.6392157 , 0.22352941, 0.37254903],\n",
      "         [0.6039216 , 0.22352941, 0.36078432],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]],\n",
      "\n",
      "        [[0.5568628 , 0.1764706 , 0.3137255 ],\n",
      "         [0.54901963, 0.18039216, 0.3137255 ],\n",
      "         [0.5372549 , 0.20392157, 0.3254902 ],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]]],\n",
      "\n",
      "\n",
      "       [[[0.8039216 , 0.8117647 , 0.7607843 ],\n",
      "         [0.8117647 , 0.81960785, 0.7647059 ],\n",
      "         [0.827451  , 0.83137256, 0.7764706 ],\n",
      "         ...,\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08627451, 0.09019608, 0.06666667],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.7921569 , 0.8       , 0.7490196 ],\n",
      "         [0.8039216 , 0.8117647 , 0.75686276],\n",
      "         [0.8235294 , 0.827451  , 0.77254903],\n",
      "         ...,\n",
      "         [0.07450981, 0.07843138, 0.05490196],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.78039217, 0.7882353 , 0.7372549 ],\n",
      "         [0.79607844, 0.8039216 , 0.7490196 ],\n",
      "         [0.8156863 , 0.81960785, 0.7647059 ],\n",
      "         ...,\n",
      "         [0.07058824, 0.07450981, 0.05098039],\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.75686276, 0.65882355, 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7372549 , 0.42745098, 0.27450982],\n",
      "         [0.7490196 , 0.4392157 , 0.2784314 ],\n",
      "         [0.75686276, 0.44705883, 0.28627452]],\n",
      "\n",
      "        [[0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7490196 , 0.42745098, 0.2784314 ],\n",
      "         [0.7607843 , 0.4392157 , 0.28235295],\n",
      "         [0.77254903, 0.4509804 , 0.29411766]],\n",
      "\n",
      "        [[0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.75686276, 0.6666667 , 0.5411765 ],\n",
      "         ...,\n",
      "         [0.7529412 , 0.43137255, 0.28235295],\n",
      "         [0.7647059 , 0.44313726, 0.28627452],\n",
      "         [0.7764706 , 0.45490196, 0.29803923]]]], dtype=float32), [array([4, 6, 3, 3]), array([5, 4, 4, 4]), array([1, 1, 1, 0])]).\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 204, in generator_py_func\n",
      "    flattened_values = nest.flatten_up_to(output_types, values)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 377, in flatten_up_to\n",
      "    assert_shallow_structure(shallow_tree, input_tree)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 304, in assert_shallow_structure\n",
      "    assert_shallow_structure(shallow_branch, input_branch,\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/util/nest.py\", line 278, in assert_shallow_structure\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: If shallow structure is a sequence, input must also be a sequence. Input has type: 'list'.\n",
      "\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "\n",
      "Traceback (most recent call last):\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/ops/script_ops.py\", line 267, in __call__\n",
      "    ret = func(*args)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/autograph/impl/api.py\", line 642, in wrapper\n",
      "    return func(*args, **kwargs)\n",
      "\n",
      "  File \"/home/utk.tennessee.edu/harshvar/.local/lib/python3.10/site-packages/tensorflow/python/data/ops/from_generator_op.py\", line 206, in generator_py_func\n",
      "    raise TypeError(\n",
      "\n",
      "TypeError: `generator` yielded an element that did not match the expected structure. The expected structure was (tf.float32, (tf.int32, tf.int32, tf.int32)), but the yielded element was (array([[[[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.41960785, 0.4       , 0.3254902 ],\n",
      "         [0.3882353 , 0.3764706 , 0.30980393],\n",
      "         [0.36862746, 0.35686275, 0.2901961 ]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.42745098, 0.40784314, 0.33333334],\n",
      "         [0.4       , 0.3882353 , 0.32156864],\n",
      "         [0.38431373, 0.37254903, 0.30588236]],\n",
      "\n",
      "        [[0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         [0.36078432, 0.40392157, 0.4117647 ],\n",
      "         ...,\n",
      "         [0.44313726, 0.42352942, 0.34901962],\n",
      "         [0.41568628, 0.40392157, 0.3372549 ],\n",
      "         [0.4       , 0.3882353 , 0.32156864]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.34117648, 0.14117648, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         [0.34509805, 0.14509805, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3372549 , 0.14509805, 0.2627451 ],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.34117648, 0.14901961, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]],\n",
      "\n",
      "        [[0.3254902 , 0.14509805, 0.25882354],\n",
      "         [0.32941177, 0.14901961, 0.2627451 ],\n",
      "         [0.33333334, 0.15294118, 0.26666668],\n",
      "         ...,\n",
      "         [0.4509804 , 0.32941177, 0.21960784],\n",
      "         [0.45490196, 0.32156864, 0.21176471],\n",
      "         [0.45490196, 0.32156864, 0.21176471]]],\n",
      "\n",
      "\n",
      "       [[[0.9254902 , 0.7294118 , 0.4509804 ],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92156863, 0.7254902 , 0.44705883],\n",
      "         [0.92941177, 0.73333335, 0.45490196],\n",
      "         [0.9411765 , 0.74509805, 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        [[0.92941177, 0.72156864, 0.44705883],\n",
      "         [0.9372549 , 0.7294118 , 0.45490196],\n",
      "         [0.9490196 , 0.7411765 , 0.46666667],\n",
      "         ...,\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471],\n",
      "         [0.01176471, 0.01176471, 0.01176471]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]],\n",
      "\n",
      "        [[0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         [0.62352943, 0.34901962, 0.15686275],\n",
      "         ...,\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314],\n",
      "         [0.00784314, 0.00784314, 0.00784314]]],\n",
      "\n",
      "\n",
      "       [[[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.627451  , 0.3529412 , 0.44705883],\n",
      "         [0.6313726 , 0.34117648, 0.4392157 ],\n",
      "         [0.62352943, 0.33333334, 0.42352942]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.6431373 , 0.36862746, 0.4627451 ],\n",
      "         [0.6392157 , 0.35686275, 0.4509804 ],\n",
      "         [0.63529414, 0.34509805, 0.43529412]],\n",
      "\n",
      "        [[0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         [0.5764706 , 0.627451  , 0.6901961 ],\n",
      "         ...,\n",
      "         [0.654902  , 0.3882353 , 0.47843137],\n",
      "         [0.654902  , 0.37254903, 0.46666667],\n",
      "         [0.6431373 , 0.36078432, 0.44705883]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.8039216 , 0.26666668, 0.44705883],\n",
      "         [0.77254903, 0.2509804 , 0.42745098],\n",
      "         [0.7176471 , 0.23529412, 0.40784314],\n",
      "         ...,\n",
      "         [0.53333336, 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668],\n",
      "         [0.5294118 , 0.39215687, 0.26666668]],\n",
      "\n",
      "        [[0.6627451 , 0.23137255, 0.38431373],\n",
      "         [0.6392157 , 0.22352941, 0.37254903],\n",
      "         [0.6039216 , 0.22352941, 0.36078432],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]],\n",
      "\n",
      "        [[0.5568628 , 0.1764706 , 0.3137255 ],\n",
      "         [0.54901963, 0.18039216, 0.3137255 ],\n",
      "         [0.5372549 , 0.20392157, 0.3254902 ],\n",
      "         ...,\n",
      "         [0.5372549 , 0.39607844, 0.2627451 ],\n",
      "         [0.53333336, 0.39607844, 0.27058825],\n",
      "         [0.53333336, 0.39607844, 0.27058825]]],\n",
      "\n",
      "\n",
      "       [[[0.8039216 , 0.8117647 , 0.7607843 ],\n",
      "         [0.8117647 , 0.81960785, 0.7647059 ],\n",
      "         [0.827451  , 0.83137256, 0.7764706 ],\n",
      "         ...,\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08627451, 0.09019608, 0.06666667],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.7921569 , 0.8       , 0.7490196 ],\n",
      "         [0.8039216 , 0.8117647 , 0.75686276],\n",
      "         [0.8235294 , 0.827451  , 0.77254903],\n",
      "         ...,\n",
      "         [0.07450981, 0.07843138, 0.05490196],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ],\n",
      "         [0.08627451, 0.09019608, 0.06666667]],\n",
      "\n",
      "        [[0.78039217, 0.7882353 , 0.7372549 ],\n",
      "         [0.79607844, 0.8039216 , 0.7490196 ],\n",
      "         [0.8156863 , 0.81960785, 0.7647059 ],\n",
      "         ...,\n",
      "         [0.07058824, 0.07450981, 0.05098039],\n",
      "         [0.07843138, 0.08235294, 0.05882353],\n",
      "         [0.08235294, 0.08627451, 0.0627451 ]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.74509805, 0.654902  , 0.5294118 ],\n",
      "         [0.75686276, 0.65882355, 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7372549 , 0.42745098, 0.27450982],\n",
      "         [0.7490196 , 0.4392157 , 0.2784314 ],\n",
      "         [0.75686276, 0.44705883, 0.28627452]],\n",
      "\n",
      "        [[0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5411765 ],\n",
      "         [0.7529412 , 0.6627451 , 0.5372549 ],\n",
      "         ...,\n",
      "         [0.7490196 , 0.42745098, 0.2784314 ],\n",
      "         [0.7607843 , 0.4392157 , 0.28235295],\n",
      "         [0.77254903, 0.4509804 , 0.29411766]],\n",
      "\n",
      "        [[0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.7607843 , 0.67058825, 0.54901963],\n",
      "         [0.75686276, 0.6666667 , 0.5411765 ],\n",
      "         ...,\n",
      "         [0.7529412 , 0.43137255, 0.28235295],\n",
      "         [0.7647059 , 0.44313726, 0.28627452],\n",
      "         [0.7764706 , 0.45490196, 0.29803923]]]], dtype=float32), [array([4, 6, 3, 3]), array([5, 4, 4, 4]), array([1, 1, 1, 0])]).\n",
      "\n",
      "\n",
      "\t [[{{node PyFunc}}]]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"./fairface-img-margin025-trainval/fairface-img-margin025-trainval\"\n",
    "x = run_model(data_path, sample_percent = 0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

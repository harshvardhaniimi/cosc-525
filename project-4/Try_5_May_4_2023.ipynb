{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v-QF-BEILeC6"
   },
   "source": [
    "# Project 4\n",
    "\n",
    "Authors: Harshvardhan and Yu Jiang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:32:55.004729Z",
     "iopub.status.busy": "2023-05-03T19:32:55.004016Z",
     "iopub.status.idle": "2023-05-03T19:32:58.200639Z",
     "shell.execute_reply": "2023-05-03T19:32:58.199969Z",
     "shell.execute_reply.started": "2023-05-03T19:32:55.004679Z"
    },
    "gather": {
     "logged": 1682525955915
    },
    "id": "iRhFyN_0LeC8",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 15:32:55.397399: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2023-05-03 15:32:55.511878: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-03T19:32:59.278549Z",
     "iopub.status.busy": "2023-05-03T19:32:59.277797Z",
     "iopub.status.idle": "2023-05-03T19:32:59.283541Z",
     "shell.execute_reply": "2023-05-03T19:32:59.282502Z",
     "shell.execute_reply.started": "2023-05-03T19:32:59.278526Z"
    },
    "gather": {
     "logged": 1682525955996
    },
    "id": "9zdgO9EnLeC9",
    "outputId": "a2a0a6e3-71ed-4946-8bb0-19ba857b81fc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4aImkyuLLeC-"
   },
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:33:00.491741Z",
     "iopub.status.busy": "2023-05-03T19:33:00.491149Z",
     "iopub.status.idle": "2023-05-03T19:33:00.521622Z",
     "shell.execute_reply": "2023-05-03T19:33:00.520219Z",
     "shell.execute_reply.started": "2023-05-03T19:33:00.491689Z"
    },
    "gather": {
     "logged": 1682525958371
    },
    "id": "JpkA-SoNLeC-",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerModel():\n",
    "    def __init__(self, vocab_size, embed_dim=256, num_heads=2, num_blocks=1, ff_dim=256, maxlen=64, rate=0.1):\n",
    "        #initailize variables\n",
    "        #vocab_size: the size of the vocabulary\n",
    "        #embed_dim: the dimension of the embedding layer\n",
    "        #num_heads: the number of heads in the multi-head attention layer\n",
    "        #num_blocks: the number of transformer blocks\n",
    "        #ff_dim: the dimension of the feed forward layer\n",
    "        #maxlen: the maximum length of the input sequence\n",
    "        #rate: the dropout rate\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embed_dim = embed_dim\n",
    "        self.num_heads = num_heads\n",
    "        self.num_blocks = num_blocks\n",
    "        self.ff_dim = ff_dim\n",
    "        self.maxlen = maxlen\n",
    "        self.rate = rate\n",
    "    \n",
    "    def TransformerBlock(self, inputs):\n",
    "    # Create a causal mask for the MultiHeadAttention layer\n",
    "        seq_len = tf.shape(inputs)[1]\n",
    "        causal_mask = 1 - tf.linalg.band_part(tf.ones((seq_len, seq_len)), -1, 0)\n",
    "\n",
    "        # MultiHeadAttention layer\n",
    "        attn_layer = tf.keras.layers.MultiHeadAttention(\n",
    "            num_heads=self.num_heads,\n",
    "            key_dim=self.embed_dim // self.num_heads,\n",
    "            use_bias=True\n",
    "        )\n",
    "        attn_output = attn_layer(inputs, inputs, attention_mask=causal_mask)\n",
    "        attn_output = tf.keras.layers.Dropout(self.rate)(attn_output)\n",
    "        out1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(inputs + attn_output)\n",
    "\n",
    "        # Feed Forward Network\n",
    "        ffn_output = tf.keras.layers.Dense(self.ff_dim, activation='relu')(out1)\n",
    "        ffn_output = tf.keras.layers.Dense(self.embed_dim)(ffn_output)\n",
    "        ffn_output = tf.keras.layers.Dropout(self.rate)(ffn_output)\n",
    "\n",
    "        # LayerNormalization\n",
    "        out2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)(out1 + ffn_output)\n",
    "\n",
    "        return out2\n",
    "\n",
    "    def EmbeddingLayer(self, inputs):\n",
    "        #create the embedding layer\n",
    "        #create (1) an embedding for the tokens and (2) an embedding for the positions\n",
    "        #you can use https://keras.io/api/layers/core_layers/embedding/ Embedding class\n",
    "        #you can use tf.range to enocde positions\n",
    "        #add (1) and (2) and return the layer\n",
    "        token_embeddings = tf.keras.layers.Embedding(self.vocab_size, self.embed_dim)(inputs)\n",
    "        positions = tf.range(start=0, limit=self.maxlen, delta=1)\n",
    "        position_embeddings = tf.keras.layers.Embedding(self.maxlen, self.embed_dim)(positions)\n",
    "\n",
    "        mask = tf.cast(tf.math.equal(inputs, 0), tf.float32)\n",
    "        mask = mask[:, tf.newaxis, tf.newaxis, :]\n",
    "\n",
    "        embeddings = token_embeddings + position_embeddings\n",
    "        embeddings = tf.keras.layers.Dropout(self.rate)(embeddings)\n",
    "\n",
    "        return embeddings, mask\n",
    "    \n",
    "    def create_model(self):\n",
    "        #combine the EmbeddingLayer and num_blocks TransformerBlocks to create the model, use the Keras functional API (https://keras.io/guides/functional_api/)\n",
    "        #use the SparseCategoricalCrossentropy loss function (https://keras.io/api/losses/probabilistic_losses/#sparsecategoricalcrossentropy-class)\n",
    "        inputs = tf.keras.layers.Input(shape=(self.maxlen,))\n",
    "        embeddings, mask = self.EmbeddingLayer(inputs)\n",
    "        x = embeddings\n",
    "\n",
    "        for _ in range(self.num_blocks):\n",
    "            x = self.TransformerBlock(inputs=x)\n",
    "\n",
    "        # x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
    "        x = tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(self.vocab_size, activation='softmax'))(x)\n",
    "        x = tf.keras.layers.Dense(self.vocab_size, activation='softmax')(x)\n",
    "\n",
    "        model = tf.keras.Model(inputs=inputs, outputs=x)\n",
    "        model.compile(optimizer='adam',\n",
    "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                    metrics=['accuracy'])\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "daAZkO32LeDA"
   },
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:34:25.496568Z",
     "iopub.status.busy": "2023-05-03T19:34:25.495803Z",
     "iopub.status.idle": "2023-05-03T19:34:25.507448Z",
     "shell.execute_reply": "2023-05-03T19:34:25.506451Z",
     "shell.execute_reply.started": "2023-05-03T19:34:25.496529Z"
    },
    "gather": {
     "logged": 1682525959229
    },
    "id": "pt83GxsXLeDA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class DataSet():\n",
    "    def __init__(self, filename, len):\n",
    "        # Load the text from the file\n",
    "        with open(filename, 'r', encoding='utf-8') as f:\n",
    "            self.text = f.read()\n",
    "        self.len = len\n",
    "\n",
    "    def prep_text(self):\n",
    "        # Remove all punctuation, set to lowercase, remove duplicate spaces and other whitespace (keep newlines)\n",
    "        self.text = self.text.lower()\n",
    "        self.text = re.sub(r\"[^a-z0-9,.!?\\n]+\", \" \", self.text)\n",
    "        self.text = re.sub(r\"[\\s]+\", \" \", self.text)\n",
    "        self.text = self.text.strip()\n",
    "\n",
    "\n",
    "    def tokenize_text(self):\n",
    "        # Separate into words, create a vocab and convert the text to a list of numbers using the vocab such that each unique word is represented by its own number\n",
    "        words = self.text.split()\n",
    "        unique_words = np.unique(words)\n",
    "        self.vocab = {word: idx for idx, word in enumerate(unique_words)}\n",
    "        self.text = [self.vocab[word] for word in words]\n",
    "\n",
    "\n",
    "    def create_dataset(self):\n",
    "        # Split the tokenized data into sequences of length len, return the sequences and vocab\n",
    "        self.prep_text()\n",
    "        self.tokenize_text()\n",
    "\n",
    "        x = []\n",
    "        y = []\n",
    "        for i in range(len(self.text) - self.len):\n",
    "            x.append(self.text[i:i + self.len])\n",
    "            y.append(self.text[i + 1:i + self.len + 1])\n",
    "\n",
    "        x = np.array(x)\n",
    "        y = np.array(y)\n",
    "\n",
    "        return x, y, self.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6uhqXZELeDA"
   },
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:34:26.723844Z",
     "iopub.status.busy": "2023-05-03T19:34:26.722830Z",
     "iopub.status.idle": "2023-05-03T19:34:26.741163Z",
     "shell.execute_reply": "2023-05-03T19:34:26.739990Z",
     "shell.execute_reply.started": "2023-05-03T19:34:26.723791Z"
    },
    "gather": {
     "logged": 1682525959994
    },
    "id": "DsxN0vfdLeDA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class GenerateText:\n",
    "    def __init__(self, model, vocab, sequence_length):\n",
    "        self.model = model\n",
    "        self.vocab = vocab\n",
    "        self.sequence_length = sequence_length\n",
    "        self.index_to_word = {i: word for i, word in enumerate(vocab)}\n",
    "        self.word_to_index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "    \n",
    "    def _sample_from_logits(self, logits):\n",
    "        logits = tf.squeeze(logits)[-1]  # Use the last element of the logits\n",
    "        logits = logits.numpy() / 1.0\n",
    "        return np.random.choice(len(self.vocab), p=np.exp(logits) / np.sum(np.exp(logits)))\n",
    "\n",
    "\n",
    "    def generate_text(self, start_string, num_generate=100):\n",
    "        input_eval = [self.word_to_index[s] for s in start_string.split()]\n",
    "        input_eval = tf.keras.preprocessing.sequence.pad_sequences([input_eval], maxlen=self.sequence_length, padding='post')\n",
    "        input_eval = tf.reshape(input_eval, (1, self.sequence_length))\n",
    "\n",
    "        generated_text = []\n",
    "\n",
    "        self.model.reset_states()\n",
    "        for _ in range(num_generate):\n",
    "            predictions = self.model.call(input_eval)\n",
    "            predicted_id = self._sample_from_logits(predictions)\n",
    "\n",
    "            input_eval = tf.concat([input_eval[:, 1:], tf.expand_dims([predicted_id], 1)], axis=1)\n",
    "\n",
    "            generated_text.append(self.index_to_word[predicted_id])\n",
    "\n",
    "        return ' '.join(generated_text)\n",
    "\n",
    "    def generate_random_text(self, num_generate=100):\n",
    "        generated_text = []\n",
    "        for _ in range(num_generate):\n",
    "            random_word = random.choice(self.vocab)\n",
    "            generated_text.append(random_word)\n",
    "\n",
    "        return ' '.join(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N5G_EwKoLeDB"
   },
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:34:27.760333Z",
     "iopub.status.busy": "2023-05-03T19:34:27.759461Z",
     "iopub.status.idle": "2023-05-03T19:34:27.768833Z",
     "shell.execute_reply": "2023-05-03T19:34:27.767648Z",
     "shell.execute_reply.started": "2023-05-03T19:34:27.760281Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_model(vocab, train_data, num_epochs, num_heads):\n",
    "    vocab_size = len(vocab)\n",
    "    model = TransformerModel(vocab_size, num_heads = num_heads)\n",
    "    transformer = model.create_model()\n",
    "\n",
    "    x_train, y_train = train_data\n",
    "\n",
    "    history = transformer.fit(x_train, y_train, batch_size=32, epochs=num_epochs, validation_split=0.1)\n",
    "\n",
    "    # Print the training loss for each epoch\n",
    "    for epoch, loss in enumerate(history.history['loss'], start=1):\n",
    "        print(f'Epoch {epoch}, Loss: {loss}')\n",
    "\n",
    "    return transformer, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-26T21:08:39.059543Z",
     "iopub.status.busy": "2023-04-26T21:08:39.058808Z",
     "iopub.status.idle": "2023-04-26T21:08:39.063459Z",
     "shell.execute_reply": "2023-04-26T21:08:39.062853Z",
     "shell.execute_reply.started": "2023-04-26T21:08:39.059503Z"
    },
    "gather": {
     "logged": 1682525960853
    },
    "id": "xX9LUiqFLeDB",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_model(vocab, train_data, num_epochs, num_heads):\n",
    "#     vocab_size = len(vocab)\n",
    "#     model = TransformerModel(vocab_size = vocab_size, num_heads = num_heads)\n",
    "#     transformer = model.create_model()\n",
    "\n",
    "#     x_train, y_train = train_data\n",
    "\n",
    "#     history = transformer.fit(x_train, y_train, batch_size=32, epochs=num_epochs, validation_split=0.1)\n",
    "\n",
    "#     return transformer, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bQItwq7vMlx2"
   },
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:34:32.348081Z",
     "iopub.status.busy": "2023-05-03T19:34:32.347125Z",
     "iopub.status.idle": "2023-05-03T19:34:32.784433Z",
     "shell.execute_reply": "2023-05-03T19:34:32.783767Z",
     "shell.execute_reply.started": "2023-05-03T19:34:32.348027Z"
    },
    "gather": {
     "logged": 1682525961766
    },
    "id": "1DtxL4zdLeDC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load and preprocess the dataset\n",
    "sequence_length = 64\n",
    "data = DataSet(\"beatles.txt\", sequence_length)\n",
    "x, y, vocab = data.create_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:34:33.885636Z",
     "iopub.status.busy": "2023-05-03T19:34:33.885329Z",
     "iopub.status.idle": "2023-05-03T19:34:33.889052Z",
     "shell.execute_reply": "2023-05-03T19:34:33.888355Z",
     "shell.execute_reply.started": "2023-05-03T19:34:33.885619Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_output_to_file(output, file_name):\n",
    "    with open(file_name, 'w') as f:\n",
    "        f.write(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNIqq2s4LeDB"
   },
   "source": [
    "### Epochs = 1\n",
    "\n",
    "#### Number of Attention Heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "execution": {
     "iopub.execute_input": "2023-05-03T19:34:43.886070Z",
     "iopub.status.busy": "2023-05-03T19:34:43.885080Z",
     "iopub.status.idle": "2023-05-03T19:35:39.627054Z",
     "shell.execute_reply": "2023-05-03T19:35:39.626370Z",
     "shell.execute_reply.started": "2023-05-03T19:34:43.886030Z"
    },
    "gather": {
     "logged": 1682526399906
    },
    "id": "_6aWhjDUMfBU",
    "outputId": "9bbf3273-8d09-40c3-ec69-d6513c0e4e9e",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-03 15:34:44.742812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 43482 MB memory:  -> device: 0, name: NVIDIA A40, pci bus id: 0000:51:00.0, compute capability: 8.6\n",
      "2023-05-03 15:34:49.665236: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-03 15:34:49.701672: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7fa8cc00e070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-03 15:34:49.701721: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA A40, Compute Capability 8.6\n",
      "2023-05-03 15:34:49.717060: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-03 15:34:50.052779: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8800\n",
      "2023-05-03 15:34:50.124687: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-03 15:34:50.189238: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    }
   ],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 1\n",
    "num_heads = 2\n",
    "trained_model, training_history = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:36:26.422648Z",
     "iopub.status.busy": "2023-05-03T19:36:26.421295Z",
     "iopub.status.idle": "2023-05-03T19:36:26.429196Z",
     "shell.execute_reply": "2023-05-03T19:36:26.427907Z",
     "shell.execute_reply.started": "2023-05-03T19:36:26.422592Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_1.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:36:44.095884Z",
     "iopub.status.busy": "2023-05-03T19:36:44.095543Z",
     "iopub.status.idle": "2023-05-03T19:36:44.289405Z",
     "shell.execute_reply": "2023-05-03T19:36:44.288527Z",
     "shell.execute_reply.started": "2023-05-03T19:36:44.095865Z"
    },
    "gather": {
     "logged": 1682526771788
    },
    "id": "zkHHkwl9LeDC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "stick saw sunday give crime, surely stays matchbox da, stays\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate = GenerateText(trained_model, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:37:16.578651Z",
     "iopub.status.busy": "2023-05-03T19:37:16.578268Z",
     "iopub.status.idle": "2023-05-03T19:37:16.762092Z",
     "shell.execute_reply": "2023-05-03T19:37:16.761265Z",
     "shell.execute_reply.started": "2023-05-03T19:37:16.578632Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bits pray coming love about. disconnect armen break red spinning\n"
     ]
    }
   ],
   "source": [
    "start_string = \"happy\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:37:22.701971Z",
     "iopub.status.busy": "2023-05-03T19:37:22.701607Z",
     "iopub.status.idle": "2023-05-03T19:37:22.919298Z",
     "shell.execute_reply": "2023-05-03T19:37:22.918447Z",
     "shell.execute_reply.started": "2023-05-03T19:37:22.701952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "diverted would. boy. comfort grandchildren belonged. pie, ago kitchen overnight.\n"
     ]
    }
   ],
   "source": [
    "start_string = \"country\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Attention Heads = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:38:39.141187Z",
     "iopub.status.busy": "2023-05-03T19:38:39.140803Z",
     "iopub.status.idle": "2023-05-03T19:39:24.900369Z",
     "shell.execute_reply": "2023-05-03T19:39:24.899665Z",
     "shell.execute_reply.started": "2023-05-03T19:38:39.141165Z"
    }
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 1\n",
    "num_heads = 3\n",
    "trained_model, training_history = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:39:24.901882Z",
     "iopub.status.busy": "2023-05-03T19:39:24.901572Z",
     "iopub.status.idle": "2023-05-03T19:39:24.905605Z",
     "shell.execute_reply": "2023-05-03T19:39:24.904866Z",
     "shell.execute_reply.started": "2023-05-03T19:39:24.901860Z"
    }
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_1_heads_3.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:39:28.005957Z",
     "iopub.status.busy": "2023-05-03T19:39:28.004811Z",
     "iopub.status.idle": "2023-05-03T19:39:28.231901Z",
     "shell.execute_reply": "2023-05-03T19:39:28.231049Z",
     "shell.execute_reply.started": "2023-05-03T19:39:28.005905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "whoah butted peep meant white, yesterday. sweet, photographs knee. blue,\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate = GenerateText(trained_model, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:39:31.594689Z",
     "iopub.status.busy": "2023-05-03T19:39:31.594363Z",
     "iopub.status.idle": "2023-05-03T19:39:31.777551Z",
     "shell.execute_reply": "2023-05-03T19:39:31.776749Z",
     "shell.execute_reply.started": "2023-05-03T19:39:31.594672Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "review sdaeh specially poop heading return horse beam existence isle\n"
     ]
    }
   ],
   "source": [
    "start_string = \"happy\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:39:33.167827Z",
     "iopub.status.busy": "2023-05-03T19:39:33.167637Z",
     "iopub.status.idle": "2023-05-03T19:39:33.357240Z",
     "shell.execute_reply": "2023-05-03T19:39:33.356396Z",
     "shell.execute_reply.started": "2023-05-03T19:39:33.167812Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "turn shining happened suddenly chains wave three, bus 4, waits\n"
     ]
    }
   ],
   "source": [
    "start_string = \"country\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yGnFs2gXLeDC"
   },
   "source": [
    "### Epochs = 50\n",
    "#### Number of Heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:40:19.504799Z",
     "iopub.status.busy": "2023-05-03T19:40:19.504402Z",
     "iopub.status.idle": "2023-05-03T19:54:11.063767Z",
     "shell.execute_reply": "2023-05-03T19:54:11.062485Z",
     "shell.execute_reply.started": "2023-05-03T19:40:19.504780Z"
    },
    "id": "TaF0hHkyLeDC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "num_heads = 2\n",
    "trained_model50, training_history50 = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:54:11.067407Z",
     "iopub.status.busy": "2023-05-03T19:54:11.066487Z",
     "iopub.status.idle": "2023-05-03T19:54:11.082474Z",
     "shell.execute_reply": "2023-05-03T19:54:11.081378Z",
     "shell.execute_reply.started": "2023-05-03T19:54:11.067354Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_50_heads_2.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:54:11.084960Z",
     "iopub.status.busy": "2023-05-03T19:54:11.084146Z",
     "iopub.status.idle": "2023-05-03T19:54:11.273836Z",
     "shell.execute_reply": "2023-05-03T19:54:11.273093Z",
     "shell.execute_reply.started": "2023-05-03T19:54:11.084911Z"
    },
    "id": "wX0Do9rWLeDC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "be? fly. to, bell haze. child, think! lizzie you moonlight\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate50 = GenerateText(trained_model50, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text50 = generate50.generate_text(start_string, num_generate=10)\n",
    "print(generated_text50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:54:38.447877Z",
     "iopub.status.busy": "2023-05-03T19:54:38.447546Z",
     "iopub.status.idle": "2023-05-03T19:54:38.645362Z",
     "shell.execute_reply": "2023-05-03T19:54:38.644512Z",
     "shell.execute_reply.started": "2023-05-03T19:54:38.447857Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "minds them, people n letter, party. turing customer, buys party.\n"
     ]
    }
   ],
   "source": [
    "start_string = \"happy\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:54:39.590692Z",
     "iopub.status.busy": "2023-05-03T19:54:39.590463Z",
     "iopub.status.idle": "2023-05-03T19:54:39.783159Z",
     "shell.execute_reply": "2023-05-03T19:54:39.782303Z",
     "shell.execute_reply.started": "2023-05-03T19:54:39.590673Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shirt, magical knickers postcards tuned ties, pam. pass college, few\n"
     ]
    }
   ],
   "source": [
    "start_string = \"country\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num of Heads = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T19:54:42.023287Z",
     "iopub.status.busy": "2023-05-03T19:54:42.022800Z",
     "iopub.status.idle": "2023-05-03T20:08:36.485319Z",
     "shell.execute_reply": "2023-05-03T20:08:36.484382Z",
     "shell.execute_reply.started": "2023-05-03T19:54:42.023258Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 50\n",
    "num_heads = 3\n",
    "trained_model50, training_history50 = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T20:08:36.487166Z",
     "iopub.status.busy": "2023-05-03T20:08:36.486755Z",
     "iopub.status.idle": "2023-05-03T20:08:36.495116Z",
     "shell.execute_reply": "2023-05-03T20:08:36.494281Z",
     "shell.execute_reply.started": "2023-05-03T20:08:36.487144Z"
    }
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_50_heads_3.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T20:08:36.499309Z",
     "iopub.status.busy": "2023-05-03T20:08:36.498976Z",
     "iopub.status.idle": "2023-05-03T20:08:36.655891Z",
     "shell.execute_reply": "2023-05-03T20:08:36.655003Z",
     "shell.execute_reply.started": "2023-05-03T20:08:36.499289Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "million, tuned porters disagree joker natural move hello kind ruins\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate50 = GenerateText(trained_model50, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text50 = generate50.generate_text(start_string, num_generate=10)\n",
    "print(generated_text50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T20:08:36.656919Z",
     "iopub.status.busy": "2023-05-03T20:08:36.656734Z",
     "iopub.status.idle": "2023-05-03T20:08:36.800523Z",
     "shell.execute_reply": "2023-05-03T20:08:36.799651Z",
     "shell.execute_reply.started": "2023-05-03T20:08:36.656903Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of, store mir seen, mack guaranteed lover aaaaahhhhhhhhhh.... tee band\n"
     ]
    }
   ],
   "source": [
    "start_string = \"happy\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T20:08:36.801557Z",
     "iopub.status.busy": "2023-05-03T20:08:36.801375Z",
     "iopub.status.idle": "2023-05-03T20:08:36.944695Z",
     "shell.execute_reply": "2023-05-03T20:08:36.943842Z",
     "shell.execute_reply.started": "2023-05-03T20:08:36.801540Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ob da awoke, meaningless deeper being, thinking poe. dead, jack\n"
     ]
    }
   ],
   "source": [
    "start_string = \"country\"\n",
    "generated_text = generate.generate_text(start_string, num_generate=10)\n",
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iMSGfKIELeDC"
   },
   "source": [
    "### Epochs = 100\n",
    "#### Number of Heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-03T20:08:36.945747Z",
     "iopub.status.busy": "2023-05-03T20:08:36.945558Z"
    },
    "id": "Rz5-NfyVLeDC",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "num_heads = 2\n",
    "trained_model100, training_history100 = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:57:08.587122Z",
     "iopub.status.busy": "2023-05-04T03:57:08.585904Z",
     "iopub.status.idle": "2023-05-04T03:57:08.604707Z",
     "shell.execute_reply": "2023-05-04T03:57:08.603389Z",
     "shell.execute_reply.started": "2023-05-04T03:57:08.587068Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_100_heads_2.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:57:13.581451Z",
     "iopub.status.busy": "2023-05-04T03:57:13.580271Z",
     "iopub.status.idle": "2023-05-04T03:57:13.805942Z",
     "shell.execute_reply": "2023-05-04T03:57:13.805116Z",
     "shell.execute_reply.started": "2023-05-04T03:57:13.581398Z"
    },
    "id": "IE7kB6WwLeDC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linger round banks thoughtlessly inside ice kind. friend, michelle. pain,\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate100 = GenerateText(trained_model100, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text100 = generate100.generate_text(start_string, num_generate=10)\n",
    "print(generated_text100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:57:16.297576Z",
     "iopub.status.busy": "2023-05-04T03:57:16.296967Z",
     "iopub.status.idle": "2023-05-04T03:57:16.509825Z",
     "shell.execute_reply": "2023-05-04T03:57:16.508999Z",
     "shell.execute_reply.started": "2023-05-04T03:57:16.297559Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mit would stand pigs near. jude, clothes, easy, whim, wail\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate100 = GenerateText(trained_model100, vocab, sequence_length)\n",
    "start_string = \"happy\"\n",
    "generated_text100 = generate100.generate_text(start_string, num_generate=10)\n",
    "print(generated_text100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:57:18.365641Z",
     "iopub.status.busy": "2023-05-04T03:57:18.365351Z",
     "iopub.status.idle": "2023-05-04T03:57:18.569647Z",
     "shell.execute_reply": "2023-05-04T03:57:18.568837Z",
     "shell.execute_reply.started": "2023-05-04T03:57:18.365624Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "walked bed ah peanuts aware. habit age based rita club\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate100 = GenerateText(trained_model100, vocab, sequence_length)\n",
    "start_string = \"country\"\n",
    "generated_text100 = generate100.generate_text(start_string, num_generate=10)\n",
    "print(generated_text100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Heads = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 100\n",
    "num_heads = 3\n",
    "trained_model100, training_history100 = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:57:23.685623Z",
     "iopub.status.busy": "2023-05-04T03:57:23.685316Z",
     "iopub.status.idle": "2023-05-04T03:57:23.693880Z",
     "shell.execute_reply": "2023-05-04T03:57:23.693090Z",
     "shell.execute_reply.started": "2023-05-04T03:57:23.685605Z"
    }
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_100_heads_3.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:57:58.100825Z",
     "iopub.status.busy": "2023-05-04T03:57:58.099634Z",
     "iopub.status.idle": "2023-05-04T03:57:58.325671Z",
     "shell.execute_reply": "2023-05-04T03:57:58.324818Z",
     "shell.execute_reply.started": "2023-05-04T03:57:58.100770Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sermon risk di your, ev brother imitate armen skies, knee.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate100 = GenerateText(trained_model100, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text100 = generate100.generate_text(start_string, num_generate=10)\n",
    "print(generated_text100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:58:08.111505Z",
     "iopub.status.busy": "2023-05-04T03:58:08.111157Z",
     "iopub.status.idle": "2023-05-04T03:58:08.322688Z",
     "shell.execute_reply": "2023-05-04T03:58:08.321841Z",
     "shell.execute_reply.started": "2023-05-04T03:58:08.111487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "place, mmm. row boac cries yer hate. day, upset already\n"
     ]
    }
   ],
   "source": [
    "start_string = \"happy\"\n",
    "generated_text100 = generate100.generate_text(start_string, num_generate=10)\n",
    "print(generated_text100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:58:15.911738Z",
     "iopub.status.busy": "2023-05-04T03:58:15.911375Z",
     "iopub.status.idle": "2023-05-04T03:58:16.125740Z",
     "shell.execute_reply": "2023-05-04T03:58:16.124910Z",
     "shell.execute_reply.started": "2023-05-04T03:58:15.911719Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "falling, picking sha 15 returned younger, saw screen buys owww!\n"
     ]
    }
   ],
   "source": [
    "start_string = \"country\"\n",
    "generated_text100 = generate100.generate_text(start_string, num_generate=10)\n",
    "print(generated_text100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_CAmNnlAOYcs"
   },
   "source": [
    "### Epochs = 120\n",
    "#### Number of Heads = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YUAqBP9bOX9c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 120\n",
    "num_heads = 2\n",
    "trained_model120, training_history120 = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:58:21.765141Z",
     "iopub.status.busy": "2023-05-04T03:58:21.764831Z",
     "iopub.status.idle": "2023-05-04T03:58:21.773146Z",
     "shell.execute_reply": "2023-05-04T03:58:21.772357Z",
     "shell.execute_reply.started": "2023-05-04T03:58:21.765124Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_120_heads_2.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:58:23.765982Z",
     "iopub.status.busy": "2023-05-04T03:58:23.764951Z",
     "iopub.status.idle": "2023-05-04T03:58:23.989976Z",
     "shell.execute_reply": "2023-05-04T03:58:23.989164Z",
     "shell.execute_reply.started": "2023-05-04T03:58:23.765930Z"
    },
    "id": "N0uqXEQ1Oe47",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pum bother hi love fields. anyway bag. longer two. bet\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate120 = GenerateText(trained_model120, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text120 = generate120.generate_text(start_string, num_generate=10)\n",
    "print(generated_text120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:58:26.164101Z",
     "iopub.status.busy": "2023-05-04T03:58:26.163842Z",
     "iopub.status.idle": "2023-05-04T03:58:26.355862Z",
     "shell.execute_reply": "2023-05-04T03:58:26.355014Z",
     "shell.execute_reply.started": "2023-05-04T03:58:26.164084Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing hurting mattered already entschuldigst talked liverpool rent? madly backdoor\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "start_string = \"happy\"\n",
    "generated_text120 = generate120.generate_text(start_string, num_generate=10)\n",
    "print(generated_text120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:58:54.173129Z",
     "iopub.status.busy": "2023-05-04T03:58:54.172796Z",
     "iopub.status.idle": "2023-05-04T03:58:54.389911Z",
     "shell.execute_reply": "2023-05-04T03:58:54.389087Z",
     "shell.execute_reply.started": "2023-05-04T03:58:54.173110Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "harmony beginning on? carry door girlfriend true, away wall home.\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "start_string = \"country\"\n",
    "generated_text120 = generate120.generate_text(start_string, num_generate=10)\n",
    "print(generated_text120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of Heads = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture captured_output\n",
    "# Train the model\n",
    "num_epochs = 120\n",
    "num_heads = 2\n",
    "trained_model120, training_history120 = train_model(vocab, (x, y), num_epochs, num_heads = num_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_text = captured_output.stdout\n",
    "file_name = 'epochs_120_heads_3.txt'\n",
    "write_output_to_file(output_text, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:59:01.003862Z",
     "iopub.status.busy": "2023-05-04T03:59:01.003543Z",
     "iopub.status.idle": "2023-05-04T03:59:01.187763Z",
     "shell.execute_reply": "2023-05-04T03:59:01.186930Z",
     "shell.execute_reply.started": "2023-05-04T03:59:01.003844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "didn mine. enough monkey cloud, hey, works rhythm girls, sweat\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "generate120 = GenerateText(trained_model120, vocab, sequence_length)\n",
    "start_string = \"daisy\"\n",
    "generated_text120 = generate120.generate_text(start_string, num_generate=10)\n",
    "print(generated_text120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:59:03.810810Z",
     "iopub.status.busy": "2023-05-04T03:59:03.810524Z",
     "iopub.status.idle": "2023-05-04T03:59:04.015310Z",
     "shell.execute_reply": "2023-05-04T03:59:04.014493Z",
     "shell.execute_reply.started": "2023-05-04T03:59:03.810793Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "postcards presents. roll. stream, middle singer there, anymore. seashell meadows\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "start_string = \"happy\"\n",
    "generated_text120 = generate120.generate_text(start_string, num_generate=10)\n",
    "print(generated_text120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T03:59:04.263006Z",
     "iopub.status.busy": "2023-05-04T03:59:04.262752Z",
     "iopub.status.idle": "2023-05-04T03:59:04.465518Z",
     "shell.execute_reply": "2023-05-04T03:59:04.464722Z",
     "shell.execute_reply.started": "2023-05-04T03:59:04.262989Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gave rest. left chance. asleep wishing ease jetzt kids weeks,\n"
     ]
    }
   ],
   "source": [
    "# Generate text using the trained model\n",
    "start_string = \"country\"\n",
    "generated_text120 = generate120.generate_text(start_string, num_generate=10)\n",
    "print(generated_text120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bqpXVPu3LeDD"
   },
   "source": [
    "\n",
    "# Report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EZr7LufBLeDD"
   },
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we aim to develop a token-based Transformer neural network that generates lyrics in the style of the Beatles. The problem is framed as a many-to-many task, where the goal is to predict a series of words. The dataset consists of lyrics from 246 Beatles songs, which are concatenated and treated as a single long sequence. \n",
    "\n",
    "The project involves implementing the TransformerModel Class, the DataSet Class, and the GenerateText Class to create, train, and evaluate the model. The model will be trained and qualitatively evaluated using different numbers of epochs, and its performance will be assessed based on the generated text's similarity to the original Beatles lyrics. \n",
    "\n",
    "The ultimate goal is to create a model capable of generating creative and coherent lyrics that resemble the Beatles' unique style."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Network\n",
    "\n",
    "We define a TransformerModel class, which creates a Transformer-based neural network for generating Beatles-style lyrics. The model architecture consists of an embedding layer, Transformer blocks, and a dense output layer. The DataSet class loads and preprocesses the lyrics data, converting it into sequences for training. The GenerateText class is responsible for generating new text using the trained model.\n",
    "\n",
    "The model is created with TensorFlow, and its architecture includes multi-head attention, layer normalization, and dropout layers. The EmbeddingLayer method creates token and positional embeddings and combines them before feeding them into the Transformer blocks. The TransformerBlock method applies multi-head attention and feed-forward layers with skip connections and layer normalization.\n",
    "\n",
    "The DataSet class reads a text file containing Beatles lyrics, preprocesses it by removing special characters, converting to lowercase, and tokenizing it. It then creates sequences of specified length for training. The GenerateText class uses the trained model to generate new text based on a given start string or randomly selected words from the vocabulary.\n",
    "\n",
    "Finally, the train_model function trains the model with a specified number of epochs and returns the trained model and its training history. The write_output_to_file function writes the generated output to a file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUx3lSG2LeDD"
   },
   "source": [
    "## Results\n",
    "\n",
    "| Epochs | Number of Heads | Cat-Cross-Entropy Loss (Final) |\n",
    "|--------|-----------------|--------------------------------|\n",
    "| 1      | 2               | 7.1664                         |\n",
    "| 1      | 3               | 7.1611                         |\n",
    "| 50     | 2               | 6.0984621                      |\n",
    "| 50     | 3               | 6.0984640                      |\n",
    "| 100    | 2               | 6.09845                        |\n",
    "| 100    | 3               | 6.09840                        |\n",
    "| 120    | 2               | 6.09851                        |\n",
    "| 120    | 3               | 6.09847                        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not see huge improvements in the model after running it for many epochs. The lyrics are probably as meaningless/meaingful as running for one epoch. \n",
    "However, we are not huge fans of Beatles so we may be missing the context of the lyrics. It is possible that the model run through more epochs is actually generating better lyrics.\n",
    "\n",
    "The loss has nearly settled at 6.098 and further improvements are only in the fourth and fifth decimal places.\n",
    "\n",
    "For our testing purpose, we tried three starting words: daisy, happy and country. Since the transformer model can only use words that are already in the lyrics, it limits the output. We weren't able to generate full text of songs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XowmIJC7LeDD"
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "First, the text from the 'beatles.txt' file is loaded and preprocessed to create a dataset. The preprocessing involves cleaning the text by removing punctuation, setting it to lowercase, and removing duplicate spaces and other whitespace.\n",
    "\n",
    "The preprocessed text is tokenized, which involves splitting the text into words, creating a vocabulary, and converting the text to a list of numbers using the vocabulary such that each unique word is represented by its own number.\n",
    "\n",
    "The tokenized text is then split into sequences of length 64.\n",
    "\n",
    "A Transformer model is created and trained using the sequences from the dataset for different numbers of epochs (1, 50, 100, and 120 and different number of attention heads (2 and 3). For each experiment, the training progress, including loss and accuracy, is captured and written to a file with names **epochs_1_heads_2.txt**, **epochs_1_heads_3.txt**, **epochs_50_heads_2.txt**, **epochs_50_heads_3.txt**, **epochs_100_heads_2.txt**, **epochs_100_heads_3.txt**, **epochs_120_heads_2.txt**, and **epochs_120_heads_3.txt**, respectively.\n",
    "\n",
    "After training the model, you will generate text using the trained model with varying numbers of epochs. You will start the generated text with the word \"daisy\" and generate 10 words. The quality of the generated text will likely improve as the number of training epochs increases.First, the text from the 'beatles.txt' file is loaded and preprocessed to create a dataset. The preprocessing involves cleaning the text by removing punctuation, setting it to lowercase, and removing duplicate spaces and other whitespace.\n",
    "\n",
    "The preprocessed text is tokenized, which involves splitting the text into words, creating a vocabulary, and converting the text to a list of numbers using the vocabulary such that each unique word is represented by its own number.\n",
    "\n",
    "The tokenized text is then split into sequences of length 64.\n",
    "\n",
    "A Transformer model is created and trained using the sequences from the dataset for different numbers of epochs (1, 50, 100, and 120 and different number of attention heads (2 and 3). For each experiment, the training progress, including loss and accuracy, is captured and written to a file with names **epochs_1_heads_2.txt**, **epochs_1_heads_3.txt**, **epochs_50_heads_2.txt**, **epochs_50_heads_3.txt**, **epochs_100_heads_2.txt**, **epochs_100_heads_3.txt**, **epochs_120_heads_2.txt**, and **epochs_120_heads_3.txt**, respectively.\n",
    "\n",
    "After training the model, you will generate text using the trained model with varying numbers of epochs. You will start the generated text with the word \"daisy\" and generate 10 words. The quality of the generated text will likely improve as the number of training epochs increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LNgtoqiMLeDD"
   },
   "source": [
    "## How to Run Code\n",
    "\n",
    "1. Import required libraries in the first few cells and run the TransformerModel, DataSet, and GenerateText classes in the following Jupyter cells.\n",
    "\n",
    "3. Run the train_model function and the write_output_to_file functions.\n",
    "\n",
    "4. Load and preprocess the dataset in another cell. Make sure you have the \"beatles.txt\" file available in the working directory.\n",
    "\n",
    "5. Run the rest of code with train_model() with appropriate parameters for number of epochs and attention heads.\n",
    "\n",
    "6. The rest of the codes will give you the generated text using the generate_text function from the GenerateText class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# System Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T04:04:35.500720Z",
     "iopub.status.busy": "2023-05-04T04:04:35.499419Z",
     "iopub.status.idle": "2023-05-04T04:04:35.511853Z",
     "shell.execute_reply": "2023-05-04T04:04:35.510512Z",
     "shell.execute_reply.started": "2023-05-04T04:04:35.500664Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "System Information\n",
      "------------------\n",
      "CPU cores\t: 64\n",
      "Operating System\t: posix 5.15.0-69-generic\n",
      "System uptime\t: 2023-04-21 15:22:09\n",
      "Total Memory\t: 251 GB\n",
      "Swap Memory\t: 1 GB\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the number of CPU cores\n",
    "num_cores = psutil.cpu_count()\n",
    "\n",
    "# Get the operating system name and version\n",
    "os_name = f\"{psutil.os.name} {psutil.os.uname().release}\"\n",
    "\n",
    "# Get the system uptime\n",
    "uptime = psutil.boot_time()\n",
    "\n",
    "# Get the total system memory and swap memory\n",
    "total_memory = psutil.virtual_memory().total\n",
    "swap_memory = psutil.swap_memory().total\n",
    "\n",
    "# Format the output\n",
    "output = f\"\"\"\n",
    "System Information\n",
    "------------------\n",
    "CPU cores\\t: {num_cores}\n",
    "Operating System\\t: {os_name}\n",
    "System uptime\\t: {psutil.datetime.datetime.fromtimestamp(uptime).strftime(\"%Y-%m-%d %H:%M:%S\")}\n",
    "Total Memory\\t: {total_memory // (1024**3)} GB\n",
    "Swap Memory\\t: {swap_memory // (1024**3)} GB\n",
    "\"\"\"\n",
    "\n",
    "# Print the output\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-04T04:04:38.367382Z",
     "iopub.status.busy": "2023-05-04T04:04:38.366136Z",
     "iopub.status.idle": "2023-05-04T04:04:38.375178Z",
     "shell.execute_reply": "2023-05-04T04:04:38.373969Z",
     "shell.execute_reply.started": "2023-05-04T04:04:38.367328Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.12.0'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "microsoft": {
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
